# 前言-人工智能简介

## 1. 人工智能主要分支

### 1.1 主要分支介绍

通讯、感知与行动是现代人工智能的三个关键能力，在这里我们将根据这些能力/应用对这三个技术领域进行介绍:

- **计算机视觉(CV)**
- **自然语言处理(NLP)**
  - 在NLP领域中，将覆盖文本挖掘/分类、机器翻译和语音识别。
- **机器人**

### 1.2 分支一：计算机视觉

**计算机视觉(CV)是指机器感知环境的能力。**这一技术类别中的经典任务有图像形成、图像处理、图像提取和图像的三维推理。**物体检测和人脸识别是其比较成功的研究领域。**

**当前阶段:**

> 计算机视觉现已有很多应用，这表明了这类技术的成就，也让我们将其归入到应用阶段。随着深度学习的发展，机器甚至能在特定的案例中实现超越人类的表现。但是，这项技术离社会影响阶段还有一定距离，那要等到机器能在所有场景中都达到人类的同等水平才行(感知其环境的所有相关方面)。

### 1.3 分支二：语音识别

**语音识别是指识别语音(说出的语言)并将其转换成对应文本的技术。**相反的任务(文本转语音/TTS)也是这一领域内一个类似的研究主题。

**当前阶段:**

> 语音识别已经处于应用阶段很长时间了。最近几年，随着大数据和深度学习技术的发展，语音识别进展颇丰，现在已经非常接近社会影响阶段了。
> 语音识别领域仍然面临着**声纹识别**和「**鸡尾酒会效应**」等一些特殊情况的难题。
> **现代语音识别系统严重依赖于云，在离线时可能就无法取得理想的工作效果。**

### 1.4 分支三：文本挖掘/分类

**这里的文本挖掘主要是指文本分类，该技术可用于理解、组织和分类结构化或非结构化文本文档。**其涵盖的主要任务有句法分析、情绪分析和垃圾信息检测。

**当前阶段:**

> 我们将这项技术归类到应用阶段，因为现在有很多应用都已经集成了基于文本挖掘的情绪分析或垃圾信息检测技术。文本挖掘技术也在智能投顾的开发中有所应用，并且提升了用户体验。
> **文本挖掘和分类领域的一个瓶颈出现在歧义和有偏差的数据上。**

### 1.5 分支四：机器翻译

**机器翻译(MT)是利用机器的力量自动将一种自然语言(源语言)的文本翻译成另一种语言(目标语言)。**

**当前阶段:**

> 机器翻译是一个见证了大量发展历程的应用领域。该领域最近由于神经机器翻译而取得了非常显著的进展，但仍然没有全面达到专业译者的水平﹔但是，我们相信在大数据、云计算和深度学习技术的帮助下，机器翻译很快就将进入社会影响阶段。
> 在某些情况下，**俚语和行话等内容的翻译会比较困难**(受限词表问题)。
> **专业领域的机器翻译(比如医疗领域)表现通常不好。**

### 1.6 分支五：机器人

**机器人学(Robotics)研究的是机器人的设计、制造、运作和应用，以及控制它们的计算机系统、传感反馈和信息处理。**

机器人可以分成两大类：**固定机器人**和**移动机器人**。

- 固定机器人通常被用于工业生产(比如用于装配线)。
- 常见的移动机器人应用有货运机器人、空中机器人和自动载具。
- 机器人需要不同部件和系统的协作才能实现最优的作业。其中在硬件上包含传感器、反应器和控制器;另外还有能够实现感知能力的软件，比如定位、地图测绘和目标识别。

**当前阶段:**

> 自上世纪「Robot」一词诞生以来，人们已经为工业制造业设计了很多机器人。工业机器人是增长最快的应用领域，它们在20世纪80年代将这一领域带入了应用阶段。在安川电机、Fanuc、ABB、库卡等公司的努力下，我们认为进入21世纪之后，机器人领域就已经进入了社会影响阶段，此时各种工业机器人已经主宰了装配生产线。此外，软体机器人在很多领域也有广泛的应用，比如在医疗行业协助手术或在金融行业自动执行承销过程。



## 2. 机器学习流程

### 2.1 什么是机器学习

机器学习是从**数据中自动分析获得模型**，并利用**模型**对未知数据进行预测。

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/b08f38ccaaf2262f7853bed3e03e49c7.png)



### 2.2 机器学习流程

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/3321002138817b3cab107f7cdc86c9e7.png)

1. 获取数据
2. 数据基本处理
3. 特征工程
4. 机器学习(模型训练)
5. 模型评估
   - 结果达到要求，上线服务
   - 没有达到要求，重新上面步骤



#### 2.2.1 获取数据集

**数据简介:**

- 一行数据称为一个**样本**
- 一列数据称为一个**特征**

- 有些数据有**目标值(标签值)**，有些数据没有目标值

**数据类型构成:**

- 数据类型一：特征值+目标值（目标值是连续的和离散的）
- 数据类型二：只有特征值，没有目标值

**数据分割:**

- 机器学习一般的数据集会划分为两个部分︰
  - 训练数据:用于训练，构建模型
  - 测试数据:在模型检验时使用，用于评估模型是否有效。
- 划分比例:
  - 训练集:70% 80% 75%
  - 测试集:30% 20% 25%



#### 2.2.2 数据基本处理

即对数据进行缺失值、去除异常值等处理

#### 2.2.3 特征工程



##### 2.2.3.1 什么是特征工程

特征工程是使用**专业背景知识和技巧处理数据，使得特征能在机器学习算法上发挥更好的作用的过程。**

- 意义: 会直接影响机器学习的效果



##### 2.2.3.2 特征工程内容

**特征工程包含**

- 特征提取
- 特征预处理
- 特征降维

**特征提取**

- 将任意数据(如文本或图像)转换为可用于机器学习的数字特征

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/4f3b9972fde9119501897a897017ae3a.png)

**特征预处理**

- 通过一些转换函数将特征数据转换成**更加适合算法模型**的特征数据过程

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/8cdeae49690c83ac785eea19da88856f.png)

**特征降维**

- 指在某些限定条件下，降低随机变量(特征)个数，得到一组“不相关”主变量的过程

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/f384b98b8d8920ed65ed42938e6a24a8.png)



#### 2.2.4 机器学习

选择合适的算法对模型进行训练



#### 2.2.5 模型评估

对训练好的模型进行评估



## 3. 机器学习算法分类

根据**数据集组成不同**，可以把机器学习算法分为:

- 监督学习
- 无监督学习
- 半监督学习
- 强化学习

### 3.1 监督学习

定义:

- 输入数据是由输入特征值和目标值所组成。
  - 函数的输出可以是一个连续的值(称为回归)
  - 或是输出是有限个离散值（称作分类)。

#### 3.1.1 回归问题

例如︰预测房价，根据样本集拟合出一条连续曲线。

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/3e173afba3af83399f0c5a3d6cf2134e.png)

#### 3.1.2 分类问题

例如︰根据肿瘤特征判断良性还是恶性，得到的是结果是"良性"或者“恶性”，是离散的。

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/f9309a6146de44df219425ec1e9e1a54.png)



### 3.2 无监督学习

定义:

- 输入数据是由输入特征值组成，没有目标值
  - 输入数据没有被标记，也没有确定的结果。样本数据类别未知;
  - 需要根据样本间的相似性对样本集进行类别划分。

#### 3.2.1 有监督、无监督算法对比

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/ca4a4f396e19c2da2b9571745b0b30bc.png)



### 3.3 半监督学习

定义:

- 训练集同时包含有标记样本数据和未标记样本数据。

**监督学习训练方式**

- 标注全部数据，然后进行训练

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/326c9a7e56986d5933bbeec2cd4b7e82.png)

**半监督学习训练方式**

- 只标注少量数据，然后用训练出来的模型训练剩下的数据

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/6c086da7f24e3938dda47ca9bf621255.png)



### 3.4 强化学习

定义:

- 实质是make decisions 问题，即**自动进行决策**，并且可以做连续决策。

举例:

- 小孩想要走路，但在这之前，他需要先站起来，站起来之后还要保持平衡，接下来还要先迈出一条腿，是左腿还是右腿，迈出一步后还要迈出下一步。
- 小孩就是`agent`，他试图通过采取**行动**(即行走）来操纵**环境**（行走的表面)，并且从**一个状态转变到另一个状态**（即他走的每一步)，当他完成任务的子任务(即走了几步)时，孩子得到**奖励**（给巧克力吃)，并且当他不能走路时，就不会给巧克力。
- 主要包含五个元素:agent, action, reward, environment, observation;

强化学习的**目标**就是**获得最多的累计奖励**。

|          | 监督学习                               | 强化学习                                                     |
| -------- | -------------------------------------- | ------------------------------------------------------------ |
| 反馈映射 | 输出的是之间的关系，可以告诉算法什么   | 输出的是给机器的反馈reward function，即用来判断这个行为是好是坏。 |
| 反馈时间 | 做了比较坏的选择会**立刻反馈给算法**。 | 结果**反馈有延时**，有时候可能需要走了很多步以后才知道以前的某一步的选择是好还是坏。 |
| 输入特征 | 输入是**独立同分布的**。               | 面对的输入总是在变化，每当算法做出一个行为，它影响下一次决策的输入。 |



### 3.5 四种方式总结

|            | 输入                   | 输出       | 目的               | 案例               |
| ---------- | ---------------------- | ---------- | ------------------ | ------------------ |
| 监督学习   | 有标签                 | 有反馈     | 预测结果           | 猫狗分类、房价预测 |
| 无监督学习 | 无标签                 | 无反馈     | 发现潜在结构       | 物以类聚、人以群分 |
| 半监督学习 | 部分有标签、部分无标签 | 有反馈     | 降低数据标记的难度 |                    |
| 强化学习   | 决策流程及激励系统     | 一系列行动 | 长期利益最大化     | 学下棋             |



## 4. 模型评估

模型评估是模型开发过程不可或缺的一部分。它有助于发现表达数据的最佳模型和所选模型将来工作的性能如何。

按照**数据集的目标值**不同，可以把模型评估分为**分类模型评估**和**回归模型评估**。

### 4.1 分类模型评估

准确率

- 预测正确的数占样本总数的比例。

其他评价指标

- 精确率、召回率、F1-score、AUC指标等

### 4.2 回归模型评估

均方根误差(RMSE)

- RMSE是一个衡量回归模型误差率的常用公式。不过，它仅能比较误差是相同单位的模型。

$$
RMSE=\sqrt{\frac{\sum\limits_{i=1}^n(p_i-a_i)^2}{n}}
\\a=actual~target
\\ p=predicted~target
$$

举例

```
假设上面的房价预测,只有五个样本，对应的
真实值为:100,120,125,230,400
预测值为:105,119,120,230,410
```

那么使用均方根误差求解得:
$$
RMSE=\sqrt{\frac{[(100-105)^2+(120-119)^2+5^2+0^2+10^2]}{5}}=5.495
$$
**其他评价指标:相对平方误差（Relative $quared Error，RSE)、平均绝对误差（Mean AbsoluteError,MAE)、相对绝对误差(Relative Absolute Error，RAE)**



### 4.3 拟合

模型评估用于评价训练好的的模型的表现效果，其表现效果大致可以分为两类:过拟合、欠拟合。在训练过程中，你可能会遇到如下问题:

训练数据训练的很好啊，误差也不大，为什么在测试集上面有问题呢?当算法在某个数据集当中出现这种情况，可能就出现了**拟合问题**。

#### 4.3.1 欠拟合

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/1b4fee0a7fb83b6cc5dd177641bc5566.png)

因为机器学习到的天鹅特征太少了，导致区分标准太粗糙，不能准确识别出天鹅。
**欠拟合(under-fitting)︰**

- 模型学习的太过粗糙，连训练集中的样本数据特征关系都没有学出来。



#### 4.3.2 过拟合

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/8b77d0dd9589f7cefc046c7519def7ad.png)

机器已经基本能区别天鹅和其他动物了。然后，很不巧已有的天鹅图片全是白天鹅的，于是机器经过学习后，会认为天鹅的羽毛都是白的，以后看到羽毛是黑的天鹅就会认为那不是天鹅。

**过拟合(over-ftting)︰**

- 所建的机器学习模型或者是深度学习模型在训练样本中**表现得过于优越**，导致在测试数据集中表现不佳。



## 5. 深度学习

### 5.1 深度学习简介

深度学习(Deep Learning)

- (也称为深度结构学习【Deep Structured Learning】、层次学习
  【[Hierarchical Learning】或者是深度机器学习【Deep Machine Learning】 ）
- 是一类算法集合，是机器学的一个分支。
- 深度学习方法近年来，在会话识别、图像识别和对象侦测等领域表现出了惊人的准确性。

[深度学习演示](http://playground.tensorflow.org/)

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/1d42523917f67914f5b2c701a00b7476.png)

### 5.2 深度学习各层负责的内容

1层∶负责识别颜色及简单纹理

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/eac6326573987e35d82c2c353fabec96.png)

2层:一些神经元可以识别更加细化的纹理，布纹，刻纹，叶纹等

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/e3d0b57b424ba96d207cc42106b75467.png)

3层:一些神经元负责感受黑夜里的黄色烛光，高光，萤火，鸡蛋黄色等。

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/32924fa8cbb340090f9c4296d2c9f12d.png)

4层:一些神经元识别萌狗的脸，宠物形貌，圆柱体事物，七星瓢虫等的存在。

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/4638d2e8a5d070e4f14f518e00abb3b5.png)

5层:一些神经元负责识别花，黑眼圈动物，鸟，键盘，原型屋顶等。

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/1c3e0289a672e66448c380d6f64f43c3.png)



# 第一部分-机器学习

## 1. 机器学习环境配置

### 1.1 安装库

整个机器学习基础阶段会用到Matplotlib、Numpy、Pandas等库，为了统一版本号在环境中使用，将所有的库及其版本放到了文件requirements.txt当中，然后统一安装

**新建一个用于人工智能环境的虚拟环境**

```
mkvirtualenv ai
```

```
matplotlib==2.2.2
numpy==1.14.3
pandas==0.20.3
tables==3.4.2
jupyter==1.0.0
```

使用pip命令安装

```
pip3 install -r requirements.txt
```



### 1.2 jupyter notebook使用

Jupyter项目是一个非盈利的开源项目，源于2014年的ipython项目，因为它逐渐发展为支持跨所有编程语言的交互式数据科学和科学计算

- Jupyter Notebook，原名IPython Notbook，是IPython的加强网页版，一个开源Web应用程序
- 名字源自Julia、Python和R（数据科学的三种开源语言)
- 是一款程序员和科学工作者的编程/文档/笔记/展示软件
- `.ipynb`文件格式是用于计算型叙述的JSON文档格式的正式规范



## 2. Matplotlib

### 2.1 简介

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/68edd9a3dd4fad00b268bd95106d7829.png)

- 是专门用于开发2D图表(包括3D图表)
- 以渐进、交互式方式实现数据可视化

### 2.2 简单使用

1. 导入模块

```py
import matplotlib.pyplot as plt
import random
```

2. 创建数据

```py
x = range(60)
y_shanghai = [random.uniform(15,18) for i in x]
```

3. 创建画布

```py
plt.figure(figsize=(20,8),dpi=80)
# figsize:指定图的长宽
# dpi:图像清晰度
# 返回fig对象
```

4. 绘制折线图

```py
# 绘制折线图
plt.plot(x,y_shanghai)
```

5. 显示图像

```py
# 显示图像
plt.show()
```

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/27e3937b87fb67aff04ef5101ab5d562.png)

### 2.3 Matplotlib图像结构

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/1758df2629683516c0a02cd37f8e26f5.png)

### 2.4 添加x、y轴刻度

- `plt.xticks(x,**kwargs)`

  x:要显示的刻度值

- `plt.yticks(y,**kwargs)`

  y:要显示的刻度值

```py
plt.figure(figsize=(20, 8), dpi=100)
# figsize:指定图的长宽
# dpi:图像清晰度
# 返回fig对象

# 构造x轴刻度标签
x_ticks_label = ["11点{}分".format(i) for i in x]
# 构造y轴刻度标签
y_ticks = range(40)

# 绘制折线图
plt.plot(x, y_shanghai)

# 修改x,y轴坐标的刻度显示
plt.xticks(x[::5], x_ticks_label[::5])
plt.yticks(y_ticks[::5])
# 显示图像

plt.show()
```



### 2.5 解决中文显示问题

在Python脚本中动态设置matplotlibrc

```py
from pylab import mpl
# 设置中文字体
mpl.rcParams['font.sans-serif'] = ['SimHei']
```

有时候，字体更改后，会导致坐标轴中的部分字符无法正常显示，此时需要更改`axes.unicode_minus`参数:

```py
# 设置正常显示符号
mpl.rcParams["axes.unicode_minus"] = False
```

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/2cf32349ca3542f4ffe4d79ed132aef4.png)

### 2.6 其他基本操作

#### 2.6.1 添加网格显示

```py
plt.grid(True,linestyle='--',alpha=0.5)
```

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/305731b80a1257093a98736124907d1b.png)

#### 2.6.2 添加描述信息

添加x轴、y轴描述信息及标题

```py
plt.xlabel("时间")
plt.ylabel("温度")
plt.title("中午11点到12点之间的温度变化图示",fontsize=20)
```

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/3f2fa4f34b637ad33daa46dc19883bba.png)

#### 2.6.3 保存图片

```py
plt.savefig("test.png")
```

#### 2.6.4 绘制多条线段

```py
x = range(60)
y_shanghai = [random.uniform(15, 18) for i in x]
y_beijing = [random.uniform(1, 3) for i in x]
# 绘制折线图
plt.plot(x, y_shanghai)
plt.plot(x, y_beijing)
```

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/85b38558f1a0266dabb4f5b714c5bf6e.png)

#### 2.6.5 设置图形风格

| 颜色字符 | 风格字符      |
| -------- | ------------- |
| r 红色   | - 实线        |
| g 绿色   | -- 虚线       |
| b 蓝色   | -. 点划线     |
| w 白色   | : 点虚线      |
| c 青色   | ' '留空、空格 |
| m 洋红   |               |
| y 黄色   |               |
| k 黑色   |               |

#### 2.6.6 显示图例

```py
# 绘制折线图
plt.plot(x, y_shanghai)
plt.plot(x, y_beijing)
# 显示图例
plt.legend(["上海", "北京"],loc="best")
```

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/f6696c7096c62d43f6b6c9286357bab3.png)



### 2.7 多个坐标系显示--plt.subplots

如果我们想要将上海和北京的天气图显示在同一个图的不同坐标系当中，效果如下:

可以通过subplots函数实现(旧的版本中有subplot，使用起来不方便)，推荐subplots函数

- `matplotlib.pyplot.subplots(nrows=1, ncols=1,**fig_kw)`创建一个带有多个axes(坐标系/绘图区)的图

`plt.函数名()`相当于面向过程的画图方法，`axes.set_方法名()`相当于面向对象的画图方法。



## 3. K-近邻算法

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/2069dce32cd1b284fa8b83b8eaa32710.png)

- 根据你的“邻居”来推断出你的类别

### 3.1 K-近邻算法(KNN)概念

> K Nearest Neighbor 算法⼜叫 KNN 算法，这个算法是机器学习⾥⾯⼀个⽐较经典的 算法，  总体来说 KNN 算法是相对⽐较容易理解的算法

定义

- 如果⼀个样本在特征空间中的 **k 个最相似 ( 即特征空间中最邻近 ) 的样本中的大多数属于某⼀个类别**，则该样本也属于这个类别。

距离公式

- 两个样本的距离可以通过如下公式计算，又叫欧式距离 

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/3b6706ceaccec4246824814f571d88f2.png)

**电影类型分析**

假设我们现在有几部电影

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/dd33af3eb837c399cd8d5c0bd50f845f.png)

其中?号电影不知道类别，如何去预测?我们可以利用K近邻算法的思想

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/50761f428a319e514ece6f7cbc4e707f.png)

分别计算每个电影和被预测电影的距离，然后求解

![image-20240214110701492](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/c2ecae7473d6b1e2394317c4ba9361ec.png)



**算法流程总结**

1. 计算已知类别数据集中的点与当前点之间的距离
2. 按距离递增次序排序
3. 选取与当前点距离最小的k个点
4. 统计前k个点所在的类别出现的频率
5. 返回前k个点出现频率最高的类别作为当前点的预测分类

### 3.2 k近邻算法api使用



```py
# 导入模块
from sklearn.neighbors import KNeighborsClassifier

# 1. 构建数据集
"""
解释数据集
    当y=0时 x为 1 或者 2 knn会推断出x距离1到2更近的数据 y=0
    当y=1时 x为 10 或者 20 knn会推断出x距离10到20更近的数据 y=1
"""
x = [[1], [2], [10], [20]]
y = [0, 0, 1, 1]
# 2. 模型训练
# 2.1 机器学习 KNN 分类器
knn = KNeighborsClassifier(n_neighbors=2)
# 2.2 使用fit方法训练
knn.fit(x, y)
# 3.3 使用predict方法预测
print(knn.predict([[1.5]]))  # 输出：[0]
print(knn.predict([[15]]))  # 输出：[1]
```



### 3.3 距离度量

#### 3.3.1 距离公式的基本性质

在机器学习过程中，对于函数$dist(.,.)$，若它是一"距离度量"(distance measure)，则需满足一些基本性质:

- 非负性: $dist(X_i,X_j)>=0$;
- 同一性: $dist(x_i,x_j)=0$。当且仅当$X_i=X_i$;
- 对称性: $dist(x_i,x_j)= dist(x_j,x_i)$;
- 直递性: $dist(x_i,x_j)<= dist(x_i,x_k) + dist(x_k,x_j)$

> 直递性常被直接称为“三角不等式”

#### 3.3.2 常见的距离公式

##### 3.3.2.1 欧式距离

![image-20240214112933958](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/2b581590c5e50bc86f37495bf63ee141.png)

举例

```py
# 四个点之间的欧式距离 有六个值 四个点相互组合便有6个点
X=[[1,1],[2,2],[3,3],[4,4]]
d = 1.4142 2.8284 4.2426 1.4142 2.8284 1.4142
```



##### 3.3.2.2 曼哈顿距离

在曼哈顿街区要从一个十字路口开车到另一个十字路口，驾驶距离显然不是两点间的直线距离。这个实际驾驶距离就是“曼哈顿距离”。曼哈顿距离也称为“城市街区距离”(City Block distance)。

![image-20240214113319342](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/57f90ad869f2ce20f81b7d18f0aaf2aa.png)

![image-20240214113330364](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/0898ee9c1b4eca434d2f6e729ba0f13a.png)

##### 3.3.2.3 切比雪夫距离

国际象棋中，国王可以直行、横行、斜行，所以国王走一步可以移动到相邻8个方格中的任意一个。国王从格子(x1,y1)走到格子(x2,y2)最少需要多少步?这个距离就叫切比雪夫距离。

![image-20240214115029178](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/e8eda9e7498b371cdb599ef197e74e35.png)

![image-20240214115044536](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/a21885dfeb114acedaf3f3a9e14ba975.png)

##### 3.3.2.4 闵可夫斯基距离

闵氏距离不是一种距离，而是一组距离的定义，是对多个距离度量公式的概括性的表述两个n维变量a(x11,x12,...,x1n)与b(x21,x22,...,x2n)间的闵可夫斯基距离定义为

![image-20240214210014560](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/f2e81855f87e41c0f53b770dc7e69c7c.png)

其中p是一个变参数

- 当p=1时，就是曼哈顿距离;
- 当p=2时，就是欧氏距离;
- 当p->∞时，就是切比雪夫距离

根据p的不同，闵氏距离可以表示某一类/种的距离。



**闵氏距离的缺点**

1. 将各个分量的量纲(scale)，也就是“单位”相同的看待了
2. 未考虑各个分量的分布 (期望，方差等)可能是不同的



### 3.4 k值的选择

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/443c6b6d1c22aa571168ad3fc0d7229a.png)

- K值过小:
  - 容易受到异常点的影响
- k值大
  - 受到样本均衡的问题

---

**K值选择问题，李航博士的一书 ⌈统计学习方法⌋ 上所说:**

1. 选择较小的K值，就相当于用较小的领域中的训练实例进行预测，“学习”近似误差会减小，只有与输入实例较近或相似的训练实例才会对预测结果起作用，与此同时带来的问题是“学习”的估计误差会增大，换句话说，**K值的减小就意味着整体模型变得复杂，容易发生过拟合;**

2. 选择较大的K值，就相当于用较大领域中的训练实例进行预测，其优点是可以减少学习的估计误差，但缺点是学习的近似误差会增大。这时候，**与输入实例较远 (不相似的)训练实例也会对预测器作用，使预测发生错误，且K值的增大就意味着整体的模型变得简单。**

3) K=N(N为训练样本个数)，则完全不足取，因为此时无论输入实例是什么，都只是简单的预测它属于在训练实例中最多的类，模型过于简单，忽略了训练实例中大量有用信息。
**在实际应用中，K值一般取一个比较小的数值**，例如采用交叉验证法(简单来说，就是把训练数据在分成两
组:训练集和验证集)来选择最优的K值。

---

近似误差:

- 对现有训练集的训练误差，关注训练集
- 如果近似误差过小可能会出现过拟合的现象，对现有的训练集能有很好的预测，但是对未知的测试样本将会出现较大偏差的预测。
- 模型本身不是最接近最佳模型

估计误差:

- 可以理解为对测试集的测试误差，关注测试集，
- 估计误差小说明对未知数据的预测能力好.
- 模型本身最接近最佳模型。



### 3.5 kd树

实现k近邻算法时，**主要考虑的问题是如何对训练数据进行快速k近邻搜索**

这在特征空间的维数大及训练数据容量大时尤其必要。

**k近邻法最简单的实现是线性扫描(穷举搜索)，即要计算输入实例与每一个训练实例的距离。计算并存储好以后，再查找K近邻**。当训练集很大时，计算非常耗时。

为了提高KNN搜索的效率，可以考虑使用特殊的结构存储训练数据，以减小计算距离的次数。

#### 3.5.1 kd树简介

根据**KNN**每次需要预测一个点时，我们都需要计算训练数据集里每个点到这个点的距离，然后选出距离最近
的k个点进行投票。**当数据集很大时，这个计算成本非常高。**

**kd树**:为了避免每次都重新计算一遍距离，算法会把距离信息保存在一棵树里，这样在计算之前从树里查询距离信息，尽量避免重新计算。其基本原理是，**如果A和B距离很远，B和C距离很近，那么A和C的距离也很远**。有了这个信息，就可以在合适的时候跳过距离远的点。

这样优化后的算法复杂度可降低到**O(DNIog (N))**。感兴趣的读者可参阅论文: Bentley，J.L,Communications of the ACM (1975) 。

1989年，另外一种称为**Ball Tree**的算法，在kd Tree的基础上对性能进一步进行了优化。感兴趣的读者可以
搜索**Five balltree construction algorithms**来了解详细的算法信息。

**原理**

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/d6b002f47ea54166616438f0a5cc5cb6.png)

黄色的点作为根节点，上面的点归左子树，下面的点归右子树，接下来再不断地划分，分割的那条线叫做分割超平面 (splitting hyperplane) ，在一维中是一个点，二维中是线，三维的是面。

![image-20240214213006133](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/12582bafe53ea0764eed9be071bb7d4e.png)

黄色节点就是Root节点，下一层是红色，再下一层是绿色，再下一层是蓝色

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/7d481c1bfbc8bedc65eabf3f98cf5461.png)

步骤

1. 树的建立
2. 最近邻域搜索

kd树(K-dimension tree)是**一种对k维空间中的实例点进行存储以便对其进行快速检索的树形数据结构。**kd树是一种二叉树，表示对k维空间的一个划分，**构造kd树相当于不断地用垂直于坐标轴的超平面将K维空间切分，构成一系列的K维超矩形区域。**kd树的每个结点对应于一个k维超矩形区域。**利用kd树可以省去对大部分数据点的搜索，从而减少搜索的计算量。**

![image-20240214220136306](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/0a5984708d4295e59f26cc4b09a42434.png)

类比“二分查找”:给出一组数据:[9 1 4 7 2 5 0 3 8]，要查找8。如果挨个查找(线性扫描)，那么将会把数
据集都遍历一遍。而如果排一下序那数据集就变成了:[0 1 2 3 4 5 6 7 8 9]，按前一种方式我们进行了很多没有必要的查找，现在如果我们以5为分界点，那么数据集就被划分为了左右两个“簇”[0 1 2 3 4]和[6 7 8 9]。

因此，根本就没有必要进入第一个簇，可以直接进入第二个簇进行查找。把二分查找中的数据点换成k维数据点，这样的划分就变成了用超平面对k维空间的划分。空间划分就是对数据点进行分类，“挨得近”的数据点就在一个空间里面。



#### 3.5.2 构造方法

1. **构造根结点，使根结点对应于K维空间中包含所有实例点的超矩形区域;**
2. **通过递归的方法，不断地对k维空间进行切分，生成子结点。**在超矩形区域上选择一个坐标轴和在此坐标轴上的一个切分点，确定一个超平面，这个超平面通过选定的切分点并垂直于选定的坐标轴，将当前超矩形区域切分为左右两个子区域 (子结点) ;这时，实例被分到两个子区域。
3. **上述过程直到子区域内没有实例时终止(终止时的结点为叶结点)。**在此过程中，将实例保存在相应的结点上。
4. 通常，循环的选择坐标轴对空间切分，选择训练实例点在坐标轴上的中位数为切分点，这样得到的kd树是平衡的(平衡二叉树:它是一棵空树，或其左子树和右子树的深度之差的绝对值不超过1，且它的左子树和右子树都是平衡二叉树)。

KD树中每个节点是一个向量，和二叉树按照数的大小划分不同的是，KD树每层需要选定向量中的某一维，
然后根据这一维按左小右大的方式划分数据。在构建KD树时，关键需要解决2个问题:

1. **选择向量的哪一维进行划分;**
2. **如何划分数据;**

第一个问题简单的解决方法可以是随机选择某一维或按顺序选择，但是**更好的方法应该是在数据比较分散的那一维进行划分 (分散的程度可以根据方差来衡量)。**

第二个问题中，好的圳分方法可以使构建的树比较平衡，可以每次选择中位数来进行划分



### 3.6 案例鸢尾花种类预测



# 第二部分-深度学习

## 1. TensorFlow

### 1.1 TensorFlow 介绍

深度学习框架TensorFlow一经发布，就受到了广泛的关注，并在计算机视觉、音频处理、推荐系统和自然语言处理等场景下都被大面积推广使用，现在已发布2.3.0版本，接下来我们深入浅出的介绍Tensorflow的相关应用

### 1.2 张量及其操作

#### 1.2.1 张量Tensor

张量是一个多维数组。与NumPy ndarray对象类似，tf.Tensor对象也具有数据类型和形状。如下图所示:

![image-20240218205103768](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/76d229432a26653692bc7ee350263841.png)

此外，tf.Tensors可以保留在GPU中。 TensorFlow提供了丰富的操作库 (tf.add，tf.matmul,tf.linalg.inv等)，它们使用和生成tf.Tensor。在进行张量操作之前先导入相应的工具包:

#### 1.2.2 基本方法

1. 创建基础的张量

```py
import tensorflow as tf
import numpy as np

# 创建int32类型的0维张量，即标量
rank_0_tensor = tf.constant(4)
print(rank_0_tensor)
# 创建float32类型的一维张量
rank_1_tensor = tf.constant([2.0, 3.0, 4.0])
print(rank_1_tensor)
# 创建float16类型的二维张量
rank_2_tensor = tf.constant([[1, 2], [3, 4], [5, 6]], dtype=tf.float16)
print(rank_2_tensor)
```

输出结果

```
tf.Tensor(4, shape=(), dtype=int32)
tf.Tensor([2. 3. 4.], shape=(3,), dtype=float32)
tf.Tensor(
[[1. 2.]
 [3. 4.]
 [5. 6.]], shape=(3, 2), dtype=float16)
```

![image-20240221133220188](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/aa8190184b16f7bfa0097e3abad4fed9.png)

#### 1.2.3 转换为numpy

- np.array

```py
np.array(rank_2_tensor)
```

- Tensor.numpy()

```py
rank_2_tensor.numpy()
```



#### 1.2.4 常用函数

我们可以对张量做一些基本的数学运算、包括加法、元素乘法和矩阵乘法等

```py
# 定义张量a和b
a = tf.constant([[1, 2], [3, 4]])
b = tf.constant([[1, 1], [1, 1]])

print(tf.add(a, b), "\n")  # 计算张量的和
print(tf.multiply(a, b), "\n")  # 计算张量的元素乘法
print(tf.matmul(a, b), "\n")  # 计算乘法
```

输出结果

```
tf.Tensor(
[[2 3]
 [4 5]], shape=(2, 2), dtype=int32) 

tf.Tensor(
[[1 2]
 [3 4]], shape=(2, 2), dtype=int32) 

tf.Tensor(
[[3 3]
 [7 7]], shape=(2, 2), dtype=int32)
```

另外张量也可用于各种聚合运算

```py
tf.reduce_sum()  # 求和
tf.reduce_mean()  # 平均值
tf.reduce_max()  # 最大值
tf.reduce_min()  # 最小值
tf.argmax()  # 最大值的索引
tf.argmin()  # 最小值的索引
```

#### 1.2.5 变量

变量是一种特殊的张量，形状是不可变，但可以改变其中的参数。定义时的方法是

```py
my_variable = tf.Variable([[1.0, 2.0], [3.0, 4.0]])
```

也可以获取它的形状，类型等

```py
print("Shape: ", my_variable.shape)
print("DType: ", my_variable.dtype)
```



### 1.3 tf.keras介绍

tf.keras是TensorFlow 2.0的高阶API接口，为TensorFlow的代码提供了新的风格和设计模式，大大提升了TF代码的简洁性和复用性，官方也推荐使用tf.keras来进行模型设计和开发。

![image-20240221144351970](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/8b9627a45c2d42659e28c68bbbf57c58.png)

#### 1.3.1 常用模块

| 模块          | 概述                                                         |
| ------------- | ------------------------------------------------------------ |
| activations   | 激活函数                                                     |
| applications  | 预训练网络模块                                               |
| Callbacks     | 在模型训练期间被调用                                         |
| datasets      | tf.keras数据集模块，包括boston_housing，cifar10，fashion_mnist，imdb，mnist |
| layers        | Keras层API                                                   |
| losses        | 各种损失函数                                                 |
| metircs       | 各种评价指标                                                 |
| models        | 模型创建模块，以及与模型相关的API                            |
| optimizers    | 优化方法                                                     |
| preprocessing | Keras数据的预处理模块                                        |
| regularizers  | 正则化，L1,L2等                                              |
| utils         | 辅助功能实现                                                 |

#### 1.3.2 常用方法

深度学习实现的主要流程: 1.数据获取，2.数据处理，3.模型创建与训练，4 模型测试与评估，5. 模型预测

![image-20240221145024708](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/78940d29387a984c62e56a645bf30bda.png)

1. 导入tf.keras

使用`tf.keras`，首先需要在代码开始时导入`tf.keras`

```py
import tensorflow as tf
from tensorflow import keras
```

2. 数据输入

对于小的数据集，可以直接使用`numpy`格式的数据进行训练、评估模型，对于大型数据集或者要进行跨设备训练时使用`tf.data.datasets`来进行数据输入。

3. 模型构建

   - 简单模型使用Sequential进行构建

   - 复杂模型使用函数式编程来构建

   - 自定义layers

4. 训练与评估

   - 配置训练过程

   ```py
   # 配置优化方法，损失函数和评价指标
   model.compile(optimizer=tf.train.AdamOptimizer(0.001),loss='categorical_crossentropy',metrics=['accuracy'])
   ```

   - 模型训练

   ```py
   # 指明训练数据集，训练epoch，批次大小和验证集数据
   model.fit/fit_generator(dataset, epochs=10,batch_size=3,
                          validation_data=val_dataset)
   ```

   - 模型评估

   ```py
   # 指明评估数据集和批次大小
   model.evaluate(x, y, batch_size=32)
   ```

   - 模型预测

   ```py
   # 对新的样本进行预测
   model.predict(x, batch_size=32)
   ```

5. 回调函数

回调函数用在模型训练过程中，来控制模型训练行为，可以自定义回调函数，也可使用tf.keras.callbacks 内置的 callback:

- ModelCheckpoint:定期保存 checkpoints。 
- LearningRateScheduler: 动态改变学习速率。
- EarlyStopping: 当验证集上的性能不再提高时，终止训练。
- TensorBoard: 使用 TensorBoard 监测模型的状态

6. 模型的保存和恢复

   - 只保存参数

   ```py
   # 只保存模型的权重
   model.save_weights('./my_model')
   # 加载模型的权重
   model.load_weights('my_model')
   ```

   - 保存整个模型

   ```py
   # 保存模型架构与权重在h5文件中
   model.save('my_model.h5')
   # 加载模型：包括架构与对应的权重
   model = keras.models.load_model('my_model.h5')
   ```

   

### 1.4 快速入门模型

#### 1.4.1 相关库的导入



```py
# 绘图
import seaborn as sns
# 数值计算
import numpy as np
# sklearn中的相关工具
#   划分训练集和测试
from sklearn.model_selection import train_test_split
#   逻辑回归
from sklearn.linear_model import LogisticRegressionCV
# tf.keras中使用的相关工具
#   用于模型搭建
from tensorflow.keras.models import Sequential
#   建模型的层和激活方法
from tensorflow.keras.layers import Dense, Activation
#   数据处理的辅助工具
from tensorflow.keras import utils
```



#### 1.4.2 数据展示和划分

利用seaborn导入像个的数据，iris数据以dataFrame的方式在seaborn进行存储，我们读取后并进行展示

```py
# 读取数据
iris = sns.load_dataset("iris")
# 展示数据的前五行
iris.head()
```

![image-20240223142532483](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/65ee0086c281cd0d0c48dbad7e159662.png)

另外，利用seabonr中的pairplot函数探索数据特征间的关系

```py
# 将数据之间的关系进行可视化
sns.pairplot(iris, hue='species')
```

![image-20240223142630433](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/2b897ae4fe1d6e91a5c9e90c2c89146a.png)

将数据划分为训练集和测试集：从iris dataframe中提取原始数据，将花瓣和萼片数据保存在数组X中，表情保存在相应的数组y中:

```py
# 花瓣和花萼的数据
X = iris.values[:, :4]
# 标签值
y = iris.values[:, 4]
```

利用train_test_split完成数据集划分

```py
# 将数据集划分为训练集和测试集
train_X, test_X, train_y, test_y = train_test_split(X, y, train_size=0.5, test_size=0.5, random_state=0)
```



#### 1.4.3 sklearn实现

利用逻辑回归的分类器，并使用交叉验证的方法来选择最优的超参数，实例化LogisticRegressionCV分类器，并使用fit方法进行训练:

```py
# 实例化分类器
lr = LogisticRegressionCV()
# 训练
lr.fit(train_X, train_y)
```

利用训练好的分类器进行预测，并计算准确率

```py
# 计算准确率
print("Accuracy = {:.2f}".format(lr.score(test_X, test_y)))
```

逻辑回归的准确率为:

```py
Accuracy = 0.93
```



#### 1.4.4 tf.keras实现

在sklearn中我们只要实例化分类器并利用ft方法进行训练，最后衡量它的性能就可以了，那在tf.keras中与在sklearn非常相似，不同的是:

- 构建分类器时需要进行模型搭建
- 数据采集时，sklearn可以接收字符串型的标签，如:“setosa”，但是在tf.keras中需要对标签值进行热编码，如下所示:

![image-20240223155810247](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/bcd6b4ef06e364e985fd9f9c405b029a.png)

有很多方法可以实现热编码，比如pandas中的get_dummies0,在这里我们使用tf.keras中的方法进行热编码:

```py
#进行热编码
def one_hot_encode_object_array(arr):
	#去重获取全部的类别
	uniques，ids = np.unique(arr, return_inverse=True)
	#返回热编码的结果
	return utils.to_categorical(ids, len(uniques))
```

##### 1.4.4.1 数据处理

接下来对标签纸进行热编码

```py
# 训练集热编码
train_y_ohe = one_hot_encode_object_array(train_y)
#测试集热编码
test_y_ohe = one_hot_encode_object_array(test_y)
```

##### 1.4.4.2 模型搭建

在sklearn中，模型都是现成的。tf.Keras是一个神经网络库,我们需要根据数据和标签值构建神经网络。神经网络可以发现特征与标签之间的复杂关系。神经网络是一个高度结构化的图，其中包含一个或多个隐藏层。每个隐藏层都包含一个或多个神经元。神经网络有多种类别，该程序使用的是密集型神经网络，也称为全连接神经网络:一个层中的神经元将从上一层中的每个神经元获取输入连接。例如，图 2 显示了一个密集型神经网络，其中包含1 个输入层、2个隐藏层以及1个输出层
如下图所示:

![image-20240224121342401](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/4c19fa61d3bbfa88826a85859eb4073e.png)

上图 中的模型经过训练并馈送未标记的样本时，它会产生3 个预测结果:相应尾花属于指定品种的可能性。对于该示例，输出预测结果的总和是 1.0。该预测结果分解如下:山尾为 0.02，变色鸢尾为 0.95，维吉尼亚鸢尾为 0.03。这意味着该模型预测某个无标签鸢尾花样本是变色鸢尾的概率为95%。

TensorFlow `tf.keras` API是创建模型和层的首选方式。通过该AP1，您可以轻松地构建模型并进行实验，而将所有部分连接在一起的复杂工作则由 Keras 处理。

`tf.keras.Sequential`模型是层的线性堆叠。该模型的构造函数会采用一系列层实例;在本示例中，采用的是2个密集层 (分别包含 10 个节点)以及1个输出层(包含3 个代表标签预测的节点)。第一个层的`input_shape`参数对应该数据集中的特征数量:

```py
