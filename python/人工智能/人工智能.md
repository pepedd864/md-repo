# 前言-人工智能简介

## 1. 人工智能主要分支

### 1.1 主要分支介绍

通讯、感知与行动是现代人工智能的三个关键能力，在这里我们将根据这些能力/应用对这三个技术领域进行介绍:

- **计算机视觉(CV)**
- **自然语言处理(NLP)**
  - 在NLP领域中，将覆盖文本挖掘/分类、机器翻译和语音识别。
- **机器人**

### 1.2 分支一：计算机视觉

**计算机视觉(CV)是指机器感知环境的能力。**这一技术类别中的经典任务有图像形成、图像处理、图像提取和图像的三维推理。**物体检测和人脸识别是其比较成功的研究领域。**

**当前阶段:**

> 计算机视觉现已有很多应用，这表明了这类技术的成就，也让我们将其归入到应用阶段。随着深度学习的发展，机器甚至能在特定的案例中实现超越人类的表现。但是，这项技术离社会影响阶段还有一定距离，那要等到机器能在所有场景中都达到人类的同等水平才行(感知其环境的所有相关方面)。

### 1.3 分支二：语音识别

**语音识别是指识别语音(说出的语言)并将其转换成对应文本的技术。**相反的任务(文本转语音/TTS)也是这一领域内一个类似的研究主题。

**当前阶段:**

> 语音识别已经处于应用阶段很长时间了。最近几年，随着大数据和深度学习技术的发展，语音识别进展颇丰，现在已经非常接近社会影响阶段了。
> 语音识别领域仍然面临着**声纹识别**和「**鸡尾酒会效应**」等一些特殊情况的难题。
> **现代语音识别系统严重依赖于云，在离线时可能就无法取得理想的工作效果。**

### 1.4 分支三：文本挖掘/分类

**这里的文本挖掘主要是指文本分类，该技术可用于理解、组织和分类结构化或非结构化文本文档。**其涵盖的主要任务有句法分析、情绪分析和垃圾信息检测。

**当前阶段:**

> 我们将这项技术归类到应用阶段，因为现在有很多应用都已经集成了基于文本挖掘的情绪分析或垃圾信息检测技术。文本挖掘技术也在智能投顾的开发中有所应用，并且提升了用户体验。
> **文本挖掘和分类领域的一个瓶颈出现在歧义和有偏差的数据上。**

### 1.5 分支四：机器翻译

**机器翻译(MT)是利用机器的力量自动将一种自然语言(源语言)的文本翻译成另一种语言(目标语言)。**

**当前阶段:**

> 机器翻译是一个见证了大量发展历程的应用领域。该领域最近由于神经机器翻译而取得了非常显著的进展，但仍然没有全面达到专业译者的水平﹔但是，我们相信在大数据、云计算和深度学习技术的帮助下，机器翻译很快就将进入社会影响阶段。
> 在某些情况下，**俚语和行话等内容的翻译会比较困难**(受限词表问题)。
> **专业领域的机器翻译(比如医疗领域)表现通常不好。**

### 1.6 分支五：机器人

**机器人学(Robotics)研究的是机器人的设计、制造、运作和应用，以及控制它们的计算机系统、传感反馈和信息处理。**

机器人可以分成两大类：**固定机器人**和**移动机器人**。

- 固定机器人通常被用于工业生产(比如用于装配线)。
- 常见的移动机器人应用有货运机器人、空中机器人和自动载具。
- 机器人需要不同部件和系统的协作才能实现最优的作业。其中在硬件上包含传感器、反应器和控制器;另外还有能够实现感知能力的软件，比如定位、地图测绘和目标识别。

**当前阶段:**

> 自上世纪「Robot」一词诞生以来，人们已经为工业制造业设计了很多机器人。工业机器人是增长最快的应用领域，它们在20世纪80年代将这一领域带入了应用阶段。在安川电机、Fanuc、ABB、库卡等公司的努力下，我们认为进入21世纪之后，机器人领域就已经进入了社会影响阶段，此时各种工业机器人已经主宰了装配生产线。此外，软体机器人在很多领域也有广泛的应用，比如在医疗行业协助手术或在金融行业自动执行承销过程。



## 2. 机器学习流程

### 2.1 什么是机器学习

机器学习是从**数据中自动分析获得模型**，并利用**模型**对未知数据进行预测。

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/b08f38ccaaf2262f7853bed3e03e49c7.png)



### 2.2 机器学习流程

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/3321002138817b3cab107f7cdc86c9e7.png)

1. 获取数据
2. 数据基本处理
3. 特征工程
4. 机器学习(模型训练)
5. 模型评估
   - 结果达到要求，上线服务
   - 没有达到要求，重新上面步骤



#### 2.2.1 获取数据集

**数据简介:**

- 一行数据称为一个**样本**
- 一列数据称为一个**特征**

- 有些数据有**目标值(标签值)**，有些数据没有目标值

**数据类型构成:**

- 数据类型一：特征值+目标值（目标值是连续的和离散的）
- 数据类型二：只有特征值，没有目标值

**数据分割:**

- 机器学习一般的数据集会划分为两个部分︰
  - 训练数据:用于训练，构建模型
  - 测试数据:在模型检验时使用，用于评估模型是否有效。
- 划分比例:
  - 训练集:70% 80% 75%
  - 测试集:30% 20% 25%



#### 2.2.2 数据基本处理

即对数据进行缺失值、去除异常值等处理

#### 2.2.3 特征工程



##### 2.2.3.1 什么是特征工程

特征工程是使用**专业背景知识和技巧处理数据，使得特征能在机器学习算法上发挥更好的作用的过程。**

- 意义: 会直接影响机器学习的效果



##### 2.2.3.2 特征工程内容

**特征工程包含**

- 特征提取
- 特征预处理
- 特征降维

**特征提取**

- 将任意数据(如文本或图像)转换为可用于机器学习的数字特征

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/4f3b9972fde9119501897a897017ae3a.png)

**特征预处理**

- 通过一些转换函数将特征数据转换成**更加适合算法模型**的特征数据过程

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/8cdeae49690c83ac785eea19da88856f.png)

**特征降维**

- 指在某些限定条件下，降低随机变量(特征)个数，得到一组“不相关”主变量的过程

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/f384b98b8d8920ed65ed42938e6a24a8.png)



#### 2.2.4 机器学习

选择合适的算法对模型进行训练



#### 2.2.5 模型评估

对训练好的模型进行评估



## 3. 机器学习算法分类

根据**数据集组成不同**，可以把机器学习算法分为:

- 监督学习
- 无监督学习
- 半监督学习
- 强化学习

### 3.1 监督学习

定义:

- 输入数据是由输入特征值和目标值所组成。
  - 函数的输出可以是一个连续的值(称为回归)
  - 或是输出是有限个离散值（称作分类)。

#### 3.1.1 回归问题

例如︰预测房价，根据样本集拟合出一条连续曲线。

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/3e173afba3af83399f0c5a3d6cf2134e.png)

#### 3.1.2 分类问题

例如︰根据肿瘤特征判断良性还是恶性，得到的是结果是"良性"或者“恶性”，是离散的。

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/f9309a6146de44df219425ec1e9e1a54.png)



### 3.2 无监督学习

定义:

- 输入数据是由输入特征值组成，没有目标值
  - 输入数据没有被标记，也没有确定的结果。样本数据类别未知;
  - 需要根据样本间的相似性对样本集进行类别划分。

#### 3.2.1 有监督、无监督算法对比

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/ca4a4f396e19c2da2b9571745b0b30bc.png)



### 3.3 半监督学习

定义:

- 训练集同时包含有标记样本数据和未标记样本数据。

**监督学习训练方式**

- 标注全部数据，然后进行训练

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/326c9a7e56986d5933bbeec2cd4b7e82.png)

**半监督学习训练方式**

- 只标注少量数据，然后用训练出来的模型训练剩下的数据

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/6c086da7f24e3938dda47ca9bf621255.png)



### 3.4 强化学习

定义:

- 实质是make decisions 问题，即**自动进行决策**，并且可以做连续决策。

举例:

- 小孩想要走路，但在这之前，他需要先站起来，站起来之后还要保持平衡，接下来还要先迈出一条腿，是左腿还是右腿，迈出一步后还要迈出下一步。
- 小孩就是`agent`，他试图通过采取**行动**(即行走）来操纵**环境**（行走的表面)，并且从**一个状态转变到另一个状态**（即他走的每一步)，当他完成任务的子任务(即走了几步)时，孩子得到**奖励**（给巧克力吃)，并且当他不能走路时，就不会给巧克力。
- 主要包含五个元素:agent, action, reward, environment, observation;

强化学习的**目标**就是**获得最多的累计奖励**。

|          | 监督学习                               | 强化学习                                                     |
| -------- | -------------------------------------- | ------------------------------------------------------------ |
| 反馈映射 | 输出的是之间的关系，可以告诉算法什么   | 输出的是给机器的反馈reward function，即用来判断这个行为是好是坏。 |
| 反馈时间 | 做了比较坏的选择会**立刻反馈给算法**。 | 结果**反馈有延时**，有时候可能需要走了很多步以后才知道以前的某一步的选择是好还是坏。 |
| 输入特征 | 输入是**独立同分布的**。               | 面对的输入总是在变化，每当算法做出一个行为，它影响下一次决策的输入。 |



### 3.5 四种方式总结

|            | 输入                   | 输出       | 目的               | 案例               |
| ---------- | ---------------------- | ---------- | ------------------ | ------------------ |
| 监督学习   | 有标签                 | 有反馈     | 预测结果           | 猫狗分类、房价预测 |
| 无监督学习 | 无标签                 | 无反馈     | 发现潜在结构       | 物以类聚、人以群分 |
| 半监督学习 | 部分有标签、部分无标签 | 有反馈     | 降低数据标记的难度 |                    |
| 强化学习   | 决策流程及激励系统     | 一系列行动 | 长期利益最大化     | 学下棋             |



## 4. 模型评估

模型评估是模型开发过程不可或缺的一部分。它有助于发现表达数据的最佳模型和所选模型将来工作的性能如何。

按照**数据集的目标值**不同，可以把模型评估分为**分类模型评估**和**回归模型评估**。

### 4.1 分类模型评估

准确率

- 预测正确的数占样本总数的比例。

其他评价指标

- 精确率、召回率、F1-score、AUC指标等

### 4.2 回归模型评估

均方根误差(RMSE)

- RMSE是一个衡量回归模型误差率的常用公式。不过，它仅能比较误差是相同单位的模型。

$$
\begin{align}
RMSE&=\sqrt{\frac{\sum\limits_{i=1}^n(p_i-a_i)^2}{n}} \\
a&=actual~target \\
p&=predicted~target
\end{align}
$$

举例

```
假设上面的房价预测,只有五个样本，对应的
真实值为:100,120,125,230,400
预测值为:105,119,120,230,410
```

那么使用均方根误差求解得:
$$
RMSE=\sqrt{\frac{[(100-105)^2+(120-119)^2+5^2+0^2+10^2]}{5}}=5.495
$$
**其他评价指标:相对平方误差（Relative $quared Error，RSE)、平均绝对误差（Mean AbsoluteError,MAE)、相对绝对误差(Relative Absolute Error，RAE)**



### 4.3 拟合

模型评估用于评价训练好的的模型的表现效果，其表现效果大致可以分为两类:过拟合、欠拟合。在训练过程中，你可能会遇到如下问题:

训练数据训练的很好啊，误差也不大，为什么在测试集上面有问题呢?当算法在某个数据集当中出现这种情况，可能就出现了**拟合问题**。

#### 4.3.1 欠拟合

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/1b4fee0a7fb83b6cc5dd177641bc5566.png)

因为机器学习到的天鹅特征太少了，导致区分标准太粗糙，不能准确识别出天鹅。
**欠拟合(under-fitting)︰**

- 模型学习的太过粗糙，连训练集中的样本数据特征关系都没有学出来。



#### 4.3.2 过拟合

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/8b77d0dd9589f7cefc046c7519def7ad.png)

机器已经基本能区别天鹅和其他动物了。然后，很不巧已有的天鹅图片全是白天鹅的，于是机器经过学习后，会认为天鹅的羽毛都是白的，以后看到羽毛是黑的天鹅就会认为那不是天鹅。

**过拟合(over-ftting)︰**

- 所建的机器学习模型或者是深度学习模型在训练样本中**表现得过于优越**，导致在测试数据集中表现不佳。



## 5. 深度学习

### 5.1 深度学习简介

深度学习(Deep Learning)

- (也称为深度结构学习【Deep Structured Learning】、层次学习
  【[Hierarchical Learning】或者是深度机器学习【Deep Machine Learning】 ）
- 是一类算法集合，是机器学的一个分支。
- 深度学习方法近年来，在会话识别、图像识别和对象侦测等领域表现出了惊人的准确性。

[深度学习演示](http://playground.tensorflow.org/)

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/1d42523917f67914f5b2c701a00b7476.png)

### 5.2 深度学习各层负责的内容

1层∶负责识别颜色及简单纹理

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/eac6326573987e35d82c2c353fabec96.png)

2层:一些神经元可以识别更加细化的纹理，布纹，刻纹，叶纹等

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/e3d0b57b424ba96d207cc42106b75467.png)

3层:一些神经元负责感受黑夜里的黄色烛光，高光，萤火，鸡蛋黄色等。

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/32924fa8cbb340090f9c4296d2c9f12d.png)

4层:一些神经元识别萌狗的脸，宠物形貌，圆柱体事物，七星瓢虫等的存在。

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/4638d2e8a5d070e4f14f518e00abb3b5.png)

5层:一些神经元负责识别花，黑眼圈动物，鸟，键盘，原型屋顶等。

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/1c3e0289a672e66448c380d6f64f43c3.png)



# 第一部分-机器学习

## 1. 机器学习环境配置

### 1.1 安装库

整个机器学习基础阶段会用到Matplotlib、Numpy、Pandas等库，为了统一版本号在环境中使用，将所有的库及其版本放到了文件requirements.txt当中，然后统一安装

**新建一个用于人工智能环境的虚拟环境**

```
mkvirtualenv ai
```

```
matplotlib==2.2.2
numpy==1.14.3
pandas==0.20.3
tables==3.4.2
jupyter==1.0.0
```

使用pip命令安装

```
pip3 install -r requirements.txt
```



### 1.2 jupyter notebook使用

Jupyter项目是一个非盈利的开源项目，源于2014年的ipython项目，因为它逐渐发展为支持跨所有编程语言的交互式数据科学和科学计算

- Jupyter Notebook，原名IPython Notbook，是IPython的加强网页版，一个开源Web应用程序
- 名字源自Julia、Python和R（数据科学的三种开源语言)
- 是一款程序员和科学工作者的编程/文档/笔记/展示软件
- `.ipynb`文件格式是用于计算型叙述的JSON文档格式的正式规范



## 2. Matplotlib

### 2.1 简介

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/68edd9a3dd4fad00b268bd95106d7829.png)

- 是专门用于开发2D图表(包括3D图表)
- 以渐进、交互式方式实现数据可视化

### 2.2 简单使用

1. 导入模块

```python
import matplotlib.pyplot as plt
import random
```

2. 创建数据

```python
x = range(60)
y_shanghai = [random.uniform(15,18) for i in x]
```

3. 创建画布

```python
plt.figure(figsize=(20,8),dpi=80)
# figsize:指定图的长宽
# dpi:图像清晰度
# 返回fig对象
```

4. 绘制折线图

```python
# 绘制折线图
plt.plot(x,y_shanghai)
```

5. 显示图像

```python
# 显示图像
plt.show()
```

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/27e3937b87fb67aff04ef5101ab5d562.png)

### 2.3 Matplotlib图像结构

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/1758df2629683516c0a02cd37f8e26f5.png)

### 2.4 添加x、y轴刻度

- `plt.xticks(x,**kwargs)`

  x:要显示的刻度值

- `plt.yticks(y,**kwargs)`

  y:要显示的刻度值

```python
plt.figure(figsize=(20, 8), dpi=100)
# figsize:指定图的长宽
# dpi:图像清晰度
# 返回fig对象

# 构造x轴刻度标签
x_ticks_label = ["11点{}分".format(i) for i in x]
# 构造y轴刻度标签
y_ticks = range(40)

# 绘制折线图
plt.plot(x, y_shanghai)

# 修改x,y轴坐标的刻度显示
plt.xticks(x[::5], x_ticks_label[::5])
plt.yticks(y_ticks[::5])
# 显示图像

plt.show()
```



### 2.5 解决中文显示问题

在Python脚本中动态设置matplotlibrc

```python
from pylab import mpl
# 设置中文字体
mpl.rcParams['font.sans-serif'] = ['SimHei']
```

有时候，字体更改后，会导致坐标轴中的部分字符无法正常显示，此时需要更改`axes.unicode_minus`参数:

```python
# 设置正常显示符号
mpl.rcParams["axes.unicode_minus"] = False
```

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/2cf32349ca3542f4ffe4d79ed132aef4.png)

### 2.6 其他基本操作

#### 2.6.1 添加网格显示

```python
plt.grid(True,linestyle='--',alpha=0.5)
```

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/305731b80a1257093a98736124907d1b.png)

#### 2.6.2 添加描述信息

添加x轴、y轴描述信息及标题

```python
plt.xlabel("时间")
plt.ylabel("温度")
plt.title("中午11点到12点之间的温度变化图示",fontsize=20)
```

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/3f2fa4f34b637ad33daa46dc19883bba.png)

#### 2.6.3 保存图片

```python
plt.savefig("test.png")
```

#### 2.6.4 绘制多条线段

```python
x = range(60)
y_shanghai = [random.uniform(15, 18) for i in x]
y_beijing = [random.uniform(1, 3) for i in x]
# 绘制折线图
plt.plot(x, y_shanghai)
plt.plot(x, y_beijing)
```

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/85b38558f1a0266dabb4f5b714c5bf6e.png)

#### 2.6.5 设置图形风格

| 颜色字符 | 风格字符      |
| -------- | ------------- |
| r 红色   | - 实线        |
| g 绿色   | -- 虚线       |
| b 蓝色   | -. 点划线     |
| w 白色   | : 点虚线      |
| c 青色   | ' '留空、空格 |
| m 洋红   |               |
| y 黄色   |               |
| k 黑色   |               |

#### 2.6.6 显示图例

```python
# 绘制折线图
plt.plot(x, y_shanghai)
plt.plot(x, y_beijing)
# 显示图例
plt.legend(["上海", "北京"],loc="best")
```

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/f6696c7096c62d43f6b6c9286357bab3.png)



### 2.7 多个坐标系显示--plt.subplots

如果我们想要将上海和北京的天气图显示在同一个图的不同坐标系当中，效果如下:

可以通过subplots函数实现(旧的版本中有subplot，使用起来不方便)，推荐subplots函数

- `matplotlib.pyplot.subplots(nrows=1, ncols=1,**fig_kw)`创建一个带有多个axes(坐标系/绘图区)的图

`plt.函数名()`相当于面向过程的画图方法，`axes.set_方法名()`相当于面向对象的画图方法。



## 3. K-近邻算法

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/2069dce32cd1b284fa8b83b8eaa32710.png)

- 根据你的“邻居”来推断出你的类别

### 3.1 K-近邻算法(KNN)概念

> K Nearest Neighbor 算法⼜叫 KNN 算法，这个算法是机器学习⾥⾯⼀个⽐较经典的 算法，  总体来说 KNN 算法是相对⽐较容易理解的算法

定义

- 如果⼀个样本在特征空间中的 **k 个最相似 ( 即特征空间中最邻近 ) 的样本中的大多数属于某⼀个类别**，则该样本也属于这个类别。

距离公式

- 两个样本的距离可以通过如下公式计算，又叫欧式距离 

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/3b6706ceaccec4246824814f571d88f2.png)

**电影类型分析**

假设我们现在有几部电影

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/dd33af3eb837c399cd8d5c0bd50f845f.png)

其中?号电影不知道类别，如何去预测?我们可以利用K近邻算法的思想

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/50761f428a319e514ece6f7cbc4e707f.png)

分别计算每个电影和被预测电影的距离，然后求解

![image-20240214110701492](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/c2ecae7473d6b1e2394317c4ba9361ec.png)



**算法流程总结**

1. 计算已知类别数据集中的点与当前点之间的距离
2. 按距离递增次序排序
3. 选取与当前点距离最小的k个点
4. 统计前k个点所在的类别出现的频率
5. 返回前k个点出现频率最高的类别作为当前点的预测分类

### 3.2 k近邻算法api使用



```python
# 导入模块
from sklearn.neighbors import KNeighborsClassifier

# 1. 构建数据集
"""
解释数据集
    当y=0时 x为 1 或者 2 knn会推断出x距离1到2更近的数据 y=0
    当y=1时 x为 10 或者 20 knn会推断出x距离10到20更近的数据 y=1
"""
x = [[1], [2], [10], [20]]
y = [0, 0, 1, 1]
# 2. 模型训练
# 2.1 机器学习 KNN 分类器
knn = KNeighborsClassifier(n_neighbors=2)
# 2.2 使用fit方法训练
knn.fit(x, y)
# 3.3 使用predict方法预测
print(knn.predict([[1.5]]))  # 输出：[0]
print(knn.predict([[15]]))  # 输出：[1]
```



### 3.3 距离度量

#### 3.3.1 距离公式的基本性质

在机器学习过程中，对于函数$dist(.,.)$，若它是一"距离度量"(distance measure)，则需满足一些基本性质:

- 非负性: $dist(X_i,X_j)>=0$;
- 同一性: $dist(x_i,x_j)=0$。当且仅当$X_i=X_i$;
- 对称性: $dist(x_i,x_j)= dist(x_j,x_i)$;
- 直递性: $dist(x_i,x_j)<= dist(x_i,x_k) + dist(x_k,x_j)$

> 直递性常被直接称为“三角不等式”

#### 3.3.2 常见的距离公式

##### 3.3.2.1 欧式距离

![image-20240214112933958](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/2b581590c5e50bc86f37495bf63ee141.png)

举例

```python
# 四个点之间的欧式距离 有六个值 四个点相互组合便有6个点
X=[[1,1],[2,2],[3,3],[4,4]]
d = 1.4142 2.8284 4.2426 1.4142 2.8284 1.4142
```



##### 3.3.2.2 曼哈顿距离

在曼哈顿街区要从一个十字路口开车到另一个十字路口，驾驶距离显然不是两点间的直线距离。这个实际驾驶距离就是“曼哈顿距离”。曼哈顿距离也称为“城市街区距离”(City Block distance)。

![image-20240214113319342](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/57f90ad869f2ce20f81b7d18f0aaf2aa.png)

![image-20240214113330364](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/0898ee9c1b4eca434d2f6e729ba0f13a.png)

##### 3.3.2.3 切比雪夫距离

国际象棋中，国王可以直行、横行、斜行，所以国王走一步可以移动到相邻8个方格中的任意一个。国王从格子(x1,y1)走到格子(x2,y2)最少需要多少步?这个距离就叫切比雪夫距离。

![image-20240214115029178](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/e8eda9e7498b371cdb599ef197e74e35.png)

![image-20240214115044536](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/a21885dfeb114acedaf3f3a9e14ba975.png)

##### 3.3.2.4 闵可夫斯基距离

闵氏距离不是一种距离，而是一组距离的定义，是对多个距离度量公式的概括性的表述两个n维变量a(x11,x12,...,x1n)与b(x21,x22,...,x2n)间的闵可夫斯基距离定义为

![image-20240214210014560](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/f2e81855f87e41c0f53b770dc7e69c7c.png)

其中p是一个变参数

- 当p=1时，就是曼哈顿距离;
- 当p=2时，就是欧氏距离;
- 当p->∞时，就是切比雪夫距离

根据p的不同，闵氏距离可以表示某一类/种的距离。



**闵氏距离的缺点**

1. 将各个分量的量纲(scale)，也就是“单位”相同的看待了
2. 未考虑各个分量的分布 (期望，方差等)可能是不同的



### 3.4 k值的选择

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/443c6b6d1c22aa571168ad3fc0d7229a.png)

- K值过小:
  - 容易受到异常点的影响
- k值大
  - 受到样本均衡的问题

---

**K值选择问题，李航博士的一书 ⌈统计学习方法⌋ 上所说:**

1. 选择较小的K值，就相当于用较小的领域中的训练实例进行预测，“学习”近似误差会减小，只有与输入实例较近或相似的训练实例才会对预测结果起作用，与此同时带来的问题是“学习”的估计误差会增大，换句话说，**K值的减小就意味着整体模型变得复杂，容易发生过拟合;**

2. 选择较大的K值，就相当于用较大领域中的训练实例进行预测，其优点是可以减少学习的估计误差，但缺点是学习的近似误差会增大。这时候，**与输入实例较远 (不相似的)训练实例也会对预测器作用，使预测发生错误，且K值的增大就意味着整体的模型变得简单。**

3) K=N(N为训练样本个数)，则完全不足取，因为此时无论输入实例是什么，都只是简单的预测它属于在训练实例中最多的类，模型过于简单，忽略了训练实例中大量有用信息。
**在实际应用中，K值一般取一个比较小的数值**，例如采用交叉验证法(简单来说，就是把训练数据在分成两
组:训练集和验证集)来选择最优的K值。

---

近似误差:

- 对现有训练集的训练误差，关注训练集
- 如果近似误差过小可能会出现过拟合的现象，对现有的训练集能有很好的预测，但是对未知的测试样本将会出现较大偏差的预测。
- 模型本身不是最接近最佳模型

估计误差:

- 可以理解为对测试集的测试误差，关注测试集，
- 估计误差小说明对未知数据的预测能力好.
- 模型本身最接近最佳模型。



### 3.5 kd树

实现k近邻算法时，**主要考虑的问题是如何对训练数据进行快速k近邻搜索**

这在特征空间的维数大及训练数据容量大时尤其必要。

**k近邻法最简单的实现是线性扫描(穷举搜索)，即要计算输入实例与每一个训练实例的距离。计算并存储好以后，再查找K近邻**。当训练集很大时，计算非常耗时。

为了提高KNN搜索的效率，可以考虑使用特殊的结构存储训练数据，以减小计算距离的次数。

#### 3.5.1 kd树简介

根据**KNN**每次需要预测一个点时，我们都需要计算训练数据集里每个点到这个点的距离，然后选出距离最近
的k个点进行投票。**当数据集很大时，这个计算成本非常高。**

**kd树**:为了避免每次都重新计算一遍距离，算法会把距离信息保存在一棵树里，这样在计算之前从树里查询距离信息，尽量避免重新计算。其基本原理是，**如果A和B距离很远，B和C距离很近，那么A和C的距离也很远**。有了这个信息，就可以在合适的时候跳过距离远的点。

这样优化后的算法复杂度可降低到**O(DNIog (N))**。感兴趣的读者可参阅论文: Bentley，J.L,Communications of the ACM (1975) 。

1989年，另外一种称为**Ball Tree**的算法，在kd Tree的基础上对性能进一步进行了优化。感兴趣的读者可以
搜索**Five balltree construction algorithms**来了解详细的算法信息。

**原理**

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/d6b002f47ea54166616438f0a5cc5cb6.png)

黄色的点作为根节点，上面的点归左子树，下面的点归右子树，接下来再不断地划分，分割的那条线叫做分割超平面 (splitting hyperplane) ，在一维中是一个点，二维中是线，三维的是面。

![image-20240214213006133](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/12582bafe53ea0764eed9be071bb7d4e.png)

黄色节点就是Root节点，下一层是红色，再下一层是绿色，再下一层是蓝色

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/7d481c1bfbc8bedc65eabf3f98cf5461.png)

步骤

1. 树的建立
2. 最近邻域搜索

kd树(K-dimension tree)是**一种对k维空间中的实例点进行存储以便对其进行快速检索的树形数据结构。**kd树是一种二叉树，表示对k维空间的一个划分，**构造kd树相当于不断地用垂直于坐标轴的超平面将K维空间切分，构成一系列的K维超矩形区域。**kd树的每个结点对应于一个k维超矩形区域。**利用kd树可以省去对大部分数据点的搜索，从而减少搜索的计算量。**

![image-20240214220136306](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/0a5984708d4295e59f26cc4b09a42434.png)

类比“二分查找”:给出一组数据:[9 1 4 7 2 5 0 3 8]，要查找8。如果挨个查找(线性扫描)，那么将会把数
据集都遍历一遍。而如果排一下序那数据集就变成了:[0 1 2 3 4 5 6 7 8 9]，按前一种方式我们进行了很多没有必要的查找，现在如果我们以5为分界点，那么数据集就被划分为了左右两个“簇”[0 1 2 3 4]和[6 7 8 9]。

因此，根本就没有必要进入第一个簇，可以直接进入第二个簇进行查找。把二分查找中的数据点换成k维数据点，这样的划分就变成了用超平面对k维空间的划分。空间划分就是对数据点进行分类，“挨得近”的数据点就在一个空间里面。



#### 3.5.2 构造方法

1. **构造根结点，使根结点对应于K维空间中包含所有实例点的超矩形区域;**
2. **通过递归的方法，不断地对k维空间进行切分，生成子结点。**在超矩形区域上选择一个坐标轴和在此坐标轴上的一个切分点，确定一个超平面，这个超平面通过选定的切分点并垂直于选定的坐标轴，将当前超矩形区域切分为左右两个子区域 (子结点) ;这时，实例被分到两个子区域。
3. **上述过程直到子区域内没有实例时终止(终止时的结点为叶结点)。**在此过程中，将实例保存在相应的结点上。
4. 通常，循环的选择坐标轴对空间切分，选择训练实例点在坐标轴上的中位数为切分点，这样得到的kd树是平衡的(平衡二叉树:它是一棵空树，或其左子树和右子树的深度之差的绝对值不超过1，且它的左子树和右子树都是平衡二叉树)。

KD树中每个节点是一个向量，和二叉树按照数的大小划分不同的是，KD树每层需要选定向量中的某一维，
然后根据这一维按左小右大的方式划分数据。在构建KD树时，关键需要解决2个问题:

1. **选择向量的哪一维进行划分;**
2. **如何划分数据;**

第一个问题简单的解决方法可以是随机选择某一维或按顺序选择，但是**更好的方法应该是在数据比较分散的那一维进行划分 (分散的程度可以根据方差来衡量)。**

第二个问题中，好的圳分方法可以使构建的树比较平衡，可以每次选择中位数来进行划分



### 3.6 案例鸢尾花种类预测



# 第二部分-深度学习

## 1. TensorFlow入门

### 1.1 TensorFlow 介绍

深度学习框架TensorFlow一经发布，就受到了广泛的关注，并在计算机视觉、音频处理、推荐系统和自然语言处理等场景下都被大面积推广使用，现在已发布2.3.0版本，接下来我们深入浅出的介绍Tensorflow的相关应用

### 1.2 张量及其操作

#### 1.2.1 张量Tensor

张量是一个多维数组。与NumPy ndarray对象类似，tf.Tensor对象也具有数据类型和形状。如下图所示:

![image-20240218205103768](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/76d229432a26653692bc7ee350263841.png)

此外，tf.Tensors可以保留在GPU中。 TensorFlow提供了丰富的操作库 (tf.add，tf.matmul,tf.linalg.inv等)，它们使用和生成tf.Tensor。在进行张量操作之前先导入相应的工具包:

#### 1.2.2 基本方法

1. 创建基础的张量

```python
import tensorflow as tf
import numpy as np

# 创建int32类型的0维张量，即标量
rank_0_tensor = tf.constant(4)
print(rank_0_tensor)
# 创建float32类型的一维张量
rank_1_tensor = tf.constant([2.0, 3.0, 4.0])
print(rank_1_tensor)
# 创建float16类型的二维张量
rank_2_tensor = tf.constant([[1, 2], [3, 4], [5, 6]], dtype=tf.float16)
print(rank_2_tensor)
```

输出结果

```
tf.Tensor(4, shape=(), dtype=int32)
tf.Tensor([2. 3. 4.], shape=(3,), dtype=float32)
tf.Tensor(
[[1. 2.]
 [3. 4.]
 [5. 6.]], shape=(3, 2), dtype=float16)
```

![image-20240221133220188](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/aa8190184b16f7bfa0097e3abad4fed9.png)

#### 1.2.3 转换为numpy

- np.array

```python
np.array(rank_2_tensor)
```

- Tensor.numpy()

```python
rank_2_tensor.numpy()
```



#### 1.2.4 常用函数

我们可以对张量做一些基本的数学运算、包括加法、元素乘法和矩阵乘法等

```python
# 定义张量a和b
a = tf.constant([[1, 2], [3, 4]])
b = tf.constant([[1, 1], [1, 1]])

print(tf.add(a, b), "\n")  # 计算张量的和
print(tf.multiply(a, b), "\n")  # 计算张量的元素乘法
print(tf.matmul(a, b), "\n")  # 计算乘法
```

输出结果

```
tf.Tensor(
[[2 3]
 [4 5]], shape=(2, 2), dtype=int32) 

tf.Tensor(
[[1 2]
 [3 4]], shape=(2, 2), dtype=int32) 

tf.Tensor(
[[3 3]
 [7 7]], shape=(2, 2), dtype=int32)
```

另外张量也可用于各种聚合运算

```python
tf.reduce_sum()  # 求和
tf.reduce_mean()  # 平均值
tf.reduce_max()  # 最大值
tf.reduce_min()  # 最小值
tf.argmax()  # 最大值的索引
tf.argmin()  # 最小值的索引
```

#### 1.2.5 变量

变量是一种特殊的张量，形状是不可变，但可以改变其中的参数。定义时的方法是

```python
my_variable = tf.Variable([[1.0, 2.0], [3.0, 4.0]])
```

也可以获取它的形状，类型等

```python
print("Shape: ", my_variable.shape)
print("DType: ", my_variable.dtype)
```



### 1.3 tf.keras介绍

tf.keras是TensorFlow 2.0的高阶API接口，为TensorFlow的代码提供了新的风格和设计模式，大大提升了TF代码的简洁性和复用性，官方也推荐使用tf.keras来进行模型设计和开发。

![image-20240221144351970](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/8b9627a45c2d42659e28c68bbbf57c58.png)

#### 1.3.1 常用模块

| 模块          | 概述                                                         |
| ------------- | ------------------------------------------------------------ |
| activations   | 激活函数                                                     |
| applications  | 预训练网络模块                                               |
| Callbacks     | 在模型训练期间被调用                                         |
| datasets      | tf.keras数据集模块，包括boston_housing，cifar10，fashion_mnist，imdb，mnist |
| layers        | Keras层API                                                   |
| losses        | 各种损失函数                                                 |
| metircs       | 各种评价指标                                                 |
| models        | 模型创建模块，以及与模型相关的API                            |
| optimizers    | 优化方法                                                     |
| preprocessing | Keras数据的预处理模块                                        |
| regularizers  | 正则化，L1,L2等                                              |
| utils         | 辅助功能实现                                                 |

#### 1.3.2 常用方法

深度学习实现的主要流程: 1.数据获取，2.数据处理，3.模型创建与训练，4 模型测试与评估，5. 模型预测

![image-20240221145024708](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/78940d29387a984c62e56a645bf30bda.png)

1. 导入tf.keras

使用`tf.keras`，首先需要在代码开始时导入`tf.keras`

```python
import tensorflow as tf
from tensorflow import keras
```

2. 数据输入

对于小的数据集，可以直接使用`numpy`格式的数据进行训练、评估模型，对于大型数据集或者要进行跨设备训练时使用`tf.data.datasets`来进行数据输入。

3. 模型构建

   - 简单模型使用Sequential进行构建

   - 复杂模型使用函数式编程来构建

   - 自定义layers

4. 训练与评估

   - 配置训练过程

   ```python
   # 配置优化方法，损失函数和评价指标
   model.compile(optimizer=tf.train.AdamOptimizer(0.001),loss='categorical_crossentropy',metrics=['accuracy'])
   ```

   - 模型训练

   ```python
   # 指明训练数据集，训练epoch，批次大小和验证集数据
   model.fit/fit_generator(dataset, epochs=10,batch_size=3,
                          validation_data=val_dataset)
   ```

   - 模型评估

   ```python
   # 指明评估数据集和批次大小
   model.evaluate(x, y, batch_size=32)
   ```

   - 模型预测

   ```python
   # 对新的样本进行预测
   model.predict(x, batch_size=32)
   ```

5. 回调函数

回调函数用在模型训练过程中，来控制模型训练行为，可以自定义回调函数，也可使用tf.keras.callbacks 内置的 callback:

- ModelCheckpoint:定期保存 checkpoints。 
- LearningRateScheduler: 动态改变学习速率。
- EarlyStopping: 当验证集上的性能不再提高时，终止训练。
- TensorBoard: 使用 TensorBoard 监测模型的状态

6. 模型的保存和恢复

   - 只保存参数

   ```python
   # 只保存模型的权重
   model.save_weights('./my_model')
   # 加载模型的权重
   model.load_weights('my_model')
   ```

   - 保存整个模型

   ```python
   # 保存模型架构与权重在h5文件中
   model.save('my_model.h5')
   # 加载模型：包括架构与对应的权重
   model = keras.models.load_model('my_model.h5')
   ```

   

### 1.4 快速入门模型

#### 1.4.1 相关库的导入



```python
# 绘图
import seaborn as sns
# 数值计算
import numpy as np
# sklearn中的相关工具
#   划分训练集和测试
from sklearn.model_selection import train_test_split
#   逻辑回归
from sklearn.linear_model import LogisticRegressionCV
# tf.keras中使用的相关工具
#   用于模型搭建
from tensorflow.keras.models import Sequential
#   建模型的层和激活方法
from tensorflow.keras.layers import Dense, Activation
#   数据处理的辅助工具
from tensorflow.keras import utils
```



#### 1.4.2 数据展示和划分

利用seaborn导入像个的数据，iris数据以dataFrame的方式在seaborn进行存储，我们读取后并进行展示

```python
# 读取数据
iris = sns.load_dataset("iris")
# 展示数据的前五行
iris.head()
```

![image-20240227154259113](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/55d0294aea108100184e3da6e88949a5.png)

另外，利用seabonr中的pairplot函数探索数据特征间的关系

```python
# 将数据之间的关系进行可视化
sns.pairplot(iris, hue='species')
```

![image-20240227154438362](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/005ec5e75c8da0ec01cd6da25e9344b8.png)

将数据划分为训练集和测试集：从iris dataframe中提取原始数据，将花瓣和萼片数据保存在数组X中，表情保存在相应的数组y中:

```python
# 花瓣和花萼的数据
X = iris.values[:, :4]
# 标签值
y = iris.values[:, 4]
```

利用train_test_split完成数据集划分

```python
# 将数据集划分为训练集和测试集
train_X, test_X, train_y, test_y = train_test_split(X, y, train_size=0.5, test_size=0.5, random_state=0)
```



#### 1.4.3 sklearn实现

利用逻辑回归的分类器，并使用交叉验证的方法来选择最优的超参数，实例化LogisticRegressionCV分类器，并使用fit方法进行训练:

```python
# 实例化分类器
lr = LogisticRegressionCV()
# 训练
lr.fit(train_X, train_y)
```

利用训练好的分类器进行预测，并计算准确率

```python
# 计算准确率
print("Accuracy = {:.2f}".format(lr.score(test_X, test_y)))
```

逻辑回归的准确率为:

```python
Accuracy = 0.93
```



#### 1.4.4 tf.keras实现

在sklearn中我们只要实例化分类器并利用ft方法进行训练，最后衡量它的性能就可以了，那在tf.keras中与在sklearn非常相似，不同的是:

- 构建分类器时需要进行模型搭建
- 数据采集时，sklearn可以接收字符串型的标签，如:“setosa”，但是在tf.keras中需要对标签值进行热编码，如下所示:

![image-20240223155810247](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/bcd6b4ef06e364e985fd9f9c405b029a.png)

有很多方法可以实现热编码，比如pandas中的get_dummies0,在这里我们使用tf.keras中的方法进行热编码:

```python
#进行热编码
def one_hot_encode_object_array(arr):
	#去重获取全部的类别
	uniques, ids = np.unique(arr, return_inverse=True)
	#返回热编码的结果
	return utils.to_categorical(ids, len(uniques))
```

##### 1.4.4.1 数据处理

接下来对标签纸进行热编码

```python
# 训练集热编码
train_y_ohe = one_hot_encode_object_array(train_y)
#测试集热编码
test_y_ohe = one_hot_encode_object_array(test_y)
```

##### 1.4.4.2 模型搭建

在sklearn中，模型都是现成的。tf.Keras是一个神经网络库,我们需要根据数据和标签值构建神经网络。神经网络可以发现特征与标签之间的复杂关系。神经网络是一个高度结构化的图，其中包含一个或多个隐藏层。每个隐藏层都包含一个或多个神经元。神经网络有多种类别，该程序使用的是密集型神经网络，也称为全连接神经网络:一个层中的神经元将从上一层中的每个神经元获取输入连接。例如，图 2 显示了一个密集型神经网络，其中包含1 个输入层、2个隐藏层以及1个输出层
如下图所示:

![image-20240224121342401](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/4c19fa61d3bbfa88826a85859eb4073e.png)

上图 中的模型经过训练并馈送未标记的样本时，它会产生3 个预测结果:相应尾花属于指定品种的可能性。对于该示例，输出预测结果的总和是 1.0。该预测结果分解如下:山尾为 0.02，变色鸢尾为 0.95，维吉尼亚鸢尾为 0.03。这意味着该模型预测某个无标签鸢尾花样本是变色鸢尾的概率为95%。

TensorFlow `tf.keras` API是创建模型和层的首选方式。通过该AP1，您可以轻松地构建模型并进行实验，而将所有部分连接在一起的复杂工作则由 Keras 处理。

`tf.keras.Sequential`模型是层的线性堆叠。该模型的构造函数会采用一系列层实例;在本示例中，采用的是2个密集层 (分别包含 10 个节点)以及1个输出层(包含3 个代表标签预测的节点)。第一个层的`input_shape`参数对应该数据集中的特征数量:

```python
# 利用sequential方式构建模型
model = Sequential([
  # 隐藏层1，激活函数是relu，输入大小由input_shape指定
	Dense(10, activation="relu", input_shape=(4,)),
  # 隐藏层2，激活函数是relu
  Dense(10, activation="relu"),
  # 输出层
  Dense(3, activation="softmax")
])
```

通过`model.summary`可以查看模型的架构：

```python
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense (Dense)               (None, 10)                50        
                                                                 
 dense_1 (Dense)             (None, 10)                110       
                                                                 
 dense_2 (Dense)             (None, 3)                 33        
                                                                 
=================================================================
Total params: 193 (772.00 Byte)
Trainable params: 193 (772.00 Byte)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
```

激活函数可决定层中每个节点的输出形状。这些非线性关系很重要，如果没有它们，模型将等同于单个层。激活函数有很多，但隐藏层通常使用 ReLU。

模型结构

```python
utils.plot_model(model, show_shapes=True)
```

![image-20240227154513964](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/85546650e3c05ce99d841c6bf13b8680.png)

隐藏层和神经元的理想数量取决于问题和数据集。与机器学习的多个方面一样，选择最佳的神经网络形状需要一定的知识水平和实验基础。一般来说，增加隐藏层和神经元的数量通常会产生更强大的模型，而这需要更多数据才能有效地进行训练

##### 1.4.4.3 模型训练和预测 

在训练和评估阶段，我们都需要计算模型的损失。这样可以衡量模型的预测结果与预期标签有多大偏差，也就是说，模型的效果有多差。我们希望尽可能减小或优化这个值，所以我们设置优化策略和损失函数，以及模型精度的计算方法:

```python
# 设置模型的相关参数，优化器，损失函数和评价指标
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
```

转换类型

```python
train_X = np.array(train_X, dtype=np.float32)
test_X = np.array(test_X, dtype=np.float32)
```

接下来与在sklearn中相同，分别调用fit和predict方法进行预测即可。

```python
# 模型训练：expochs,训练样本送入网络中的次数，batch_size:每次训练的送入到网络中的样本个数
model.fit(train_X, train_y_ohe, epochs=10, batch_size=1, verbose=1)
```

上述代码完成的是

1. 选代每个epoch。通过一次数据集即为一个epoch。
2. 在一个epoch中，遍历训练 Dataset 中的每个样本，并获取样本的特征(x)和标签(y)。
3. 根据样本的特征进行预测，并比较预测结果和标签。衡量预测结果的不准确性，并使用所得的值计算模型的损失和梯度。
4. 使用optimizr 更新模型的变量。
5. 对每个epoch重复执行以上步骤，直到模型训练完成

训练过程展示如下:

```python
Epoch 1/10
WARNING:tensorflow:From C:\Users\Administrator\Desktop\workspace\pycharm-space\ai-learn\tensorflow-demo\.venv\lib\site-packages\keras\src\utils\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.
WARNING:tensorflow:From C:\Users\Administrator\Desktop\workspace\pycharm-space\ai-learn\tensorflow-demo\.venv\lib\site-packages\keras\src\engine\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.
75/75 [==============================] - 1s 2ms/step - loss: 4.1671 - accuracy: 0.3467
Epoch 2/10
75/75 [==============================] - 0s 2ms/step - loss: 2.0127 - accuracy: 0.0933
Epoch 3/10
75/75 [==============================] - 0s 2ms/step - loss: 1.4497 - accuracy: 0.2133
Epoch 4/10
75/75 [==============================] - 0s 3ms/step - loss: 1.1256 - accuracy: 0.4400
Epoch 5/10
75/75 [==============================] - 0s 3ms/step - loss: 0.9793 - accuracy: 0.7200
Epoch 6/10
75/75 [==============================] - 0s 2ms/step - loss: 0.9058 - accuracy: 0.6400
Epoch 7/10
75/75 [==============================] - 0s 2ms/step - loss: 0.8344 - accuracy: 0.7333
Epoch 8/10
75/75 [==============================] - 0s 2ms/step - loss: 0.7681 - accuracy: 0.7333
Epoch 9/10
75/75 [==============================] - 0s 2ms/step - loss: 0.7148 - accuracy: 0.7333
Epoch 10/10
75/75 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.7333
```

与sklearn中不同，对训练好的模型进行评估时，与sklearn.score方法对应的时tf.keras.evaluate()方法，返回的时损失函数和在complie模型时要求的指标：

```python
# 模型评估
loss, accuracy = model.evaluate(test_X, test_y_ohe, verbose=1)
```

分类器的准确率为：
```python
3/3 [==============================] - 0s 4ms/step - loss: 0.7589 - accuracy: 0.6000
```



## 2. 深度神经网络

### 2.1 神经网络

#### 2.1.1 什么是神经网络

人工神经网络 (Artificial Neural Network，简写为ANN)也简称为神经网络 (NN)，是一种模仿生物神经网络结构和功能的计算模型。人脑可以看做是一个生物神经网络，由众多的神经元连接而成。各个神经元传递复杂的电信号，树突接收到输入信号，然后对信号进行处理，通过轴突输出信号。下图是生物神经元示意图:

![image-20240227105320829](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/208b13877de597b91e0f9ff58ec8e0e5.png)

那怎么构建人工神经网络中的神经元呢?

![image-20240227105442387](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/0ad89ef2cf7ea5c3ed19421fca753319.png)

受生物神经元的启发，人工神经元接收来自其他神经元或外部源的输入，每个输入都有一个相关的权值(w)，它是根据该输入对当前神经元的重要性来确定的，对该输入加权并与其他输入求和后,
经过一个激活函数f，计算得到该神经元的输出。

那接下来我们就利用神经元来构建神经网络，相邻层之间的神经元相互连接，并给每一个连接分配一个强度，如下图所示:

![image-20240227105637466](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/84a099bd1166e9fbd3e86949fb8af43c.png)

神经网络中信息只向一个方向移动，即从输入节点向前移动，通过隐藏节点，再向输出节点移动，网络中没有循环或者环。其中的基本构件是:

- **输入层**:即输入x的那一层
- **输出层**:即输出y的那一层
- **隐藏层**: 输入层和输出层之间都是隐藏层

特点是:

- 同一层的神经元之间没有连接
- 第N层的每个神经元和第N-1层的所有神经元相连(这就是full connected的含义)，第N-1层神经
  元的输出就是第N层神经元的输入。
- 每个连接都有一个权值。

#### 2.1.2 神经元是如何工作的

人工神经元接收到一个或多个输入，对他们进行加权并相加，总和通过一个非线性函数产生输出。

![image-20240227120158873](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/cef9833be96cda423153afdf03e5724b.png)

#### 2.1.3 激活函数

在神经元中引入了激活函数，它的本质是向神经网络中引入非线性因素的，通过激活函数，神经网络就可以拟合各种曲线。如果不用激活函数，每一层输出都是上层输入的线性函数，无论神经网络有多少层，输出都是输入的线性组合，引入非线性函数作为激活函数，那输出不再是输入的线性组合，可以逼近任意函数。常用的激活函数有:

1. Sigmoid/logistics函数
2. tanh(双曲正切曲线)
3. RELU
4. LeakReLuctant
5. SoftMax

##### 2.1.3.1 Sigmoid/logistics 函数

数学表达式为
$$
f(x)=\frac{1}{1+e^{-x}}
$$
曲线如下图所示

![image-20240227153212917](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/e523ea24f0415083de675de303a14847.png)

sigmoid 在定义域内处处可导，且两侧导数逐渐趋近于0。如果X的值很大或者很小的时候，那么
函数的梯度(函数的斜率)会非常小，在反向传播的过程中，导致了向低层传递的梯度也变得非常
小。此时，网络参数很难得到有效训练。这种现象被称为梯度消失。一般来说， sigmoid 网络在5
层之内就会产生梯度消失现象。而且，该激活函数并不是以0为中心的，所以在实践中这种激活函
数使用的很少。sigmoid函数一般只用于二分类的输出层。

实现方法

```python
# 导入相应的工具包
import tensorflow as tf
import tensorflow.keras as keras
import matplotlib.pyplot as plt
import numpy as np

# 定义x的取值范围
x = np.linspace(-10, 10, 100)
# 直接使用tensorflow 实现
y = tf.nn.sigmoid(x)
# 绘图
plt.plot(x,y)
plt.grid()
```

![image-20240227155025049](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/da2c5e0b1d74370dfa60c201a578008f.png)

##### 2.1.3.2 tanh(双曲正切曲线)

数学表达式
$$
tanh(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}
$$
曲线如下图

![image-20240227155234285](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/59786800f814ce28651af32276c5bcf2.png)

tanh也是一种非常常见的激活函数。与sigmoid相比，它是以0为中心的，使得其收敛速度要比sigmoid快，减少送代次数。然而，从图中可以看出，tanh两侧的导数也为0，同样会造成梯度消失。

若使用时可在隐藏层使用tanh函数，在输出层使用sigmoid函数

实现方法为:

```python
# 定义x的取值范围
x = np.linspace(-10, 10, 100)
# 直接使用tensorflow实现
y = tf.nn.tanh(x)
#绘图
plt.plot(x, y)
```

![image-20240227160119864](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/646d2dcc539e2a4917260f7350f7864c.png)



##### 2.1.3.3 RELU

数学表达式
$$
f(x)=max(0,x)
$$
曲线如下图所示

![image-20240227160236747](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/57b9c63a718e7dca7f3c135acfab7f08.png)

ReLU是目前最常用的激活函数。从图中可以看到，当x<0时，ReLU导数为0，而当x>0时，则不存
在饱和问题。所以，ReLU 能够在x>0时保持梯度不衰减，从而缓解梯度消失问题。然而，随着训
练的推进，部分输入会落入小于0区域，导致对应权重无法更新。这种现象被称为“神经元死亡”

与sigmoid相比，RELU的优势是:

- 采用sigmoid函数，计算量大(指数运算)，反向传播求误差梯度时，求导涉及除法，计算量
  相对大，而采用Relu激活函数，整个过程的计算量节省很多。
- sigmoid函数反向传播时，很容易就会出现梯度消失的情况，从而无法完成深层网络的训练。
- Relu会使一部分神经元的输出为0，这样就造成了网络的稀疏性，并且减少了参数的相互依存
  关系，缓解了过拟合问题的发生

实现方法为

```python
x = np.linspace(-10, 10, 100)
y = tf.nn.relu(x)
# 绘图
plt.plot(x,y)
```

![image-20240227171658738](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/cf6bc8b812bbc9f3a575d64f1bb08e24.png)

##### 2.1.3.4 LeakyReLu

该激活函数是对RELU的改进

数学表达式为
$$
f(x)=max(0.1x,x)
$$
曲线如下所示

![image-20240227171941521](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/85f83bcd8dd50195d8aeb77730399a57.png)

实现方法为

```python
x=np.linspace(-10, 10, 100)
y= tf.nn.leaky_relu(x)
plt.plot(x,y)
```

![image-20240227172627012](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/25377e07fbfd2d0d533728c06403476b.png)

##### 2.1.3.5 SoftMax

softmax用于多分类过程中，它是二分类函数sigmoid在多分类上的推广，目的是将多分类的结果
以概率的形式展现出来。
计算方法如下图所示:
$$
softmax(Z_i)=\frac{e^{z_i}}{\sum_je^{z_j}}
$$


使用方法如下

![image-20240227220654071](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/67d055c3dda720491a5b84e43df14f6a.png)

**softmax直白来说就是将网络输出的logits通过softmax函数，就映射成为(0,1)的值，而这些值的累**
**和为1(满足概率的性质)，那么我们将它理解成概率，选取概率最大(也就是值对应最大的)接**
**点，作为我们的预测目标类别。**

实现，以上图中数字9的分类结果为例给大家进行演示

```python
x = tf.constant([0.2, 0.02, 0.15, 1.3, 0.5, 0.06, 1.1, 0.05, 3.75])
y = tf.nn.softmax(x)
```



##### 2.1.3.6 如何选择激活函数

 隐藏层

- 优先选择RELU激活函数
- 如果ReLu效果不好，那么尝试其他激活，如Leaky ReLu等
- 如果你使用了Relu，需要注意一下Dead Relu问题，避免出现大的梯度从而导致过多的神经元
  死亡。
- 不要使用sigmoid激活函数，可以尝试使用tanh激活函数

输出层

- 二分类问题选择sigmoid激活函数
- 多分类问题选择softmax激活函数
- 回归问题选择identity激活函数



#### 2.1.4 参数初始化

对于某一个神经元来说，需要初始化的参数有两类:一类是权重W，还有一类是偏置b,偏置b初始
化为0即可。而权重W的初始化比较重要，我们着重来介绍常见的初始化方式。

![image-20240227224925578](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/8f560ec60517bcca86484dfe5e6976d9.png)

##### 2.1.4.1 随机初始化

随机初始化从均值为0，标准差是1的高斯分布中取样，使用一些很小的值对参数W进行初始化

##### 2.1.4.2 标准初始化

权重参数初始化从区间均匀随机取值。即在(-1/d,1/Jd)均匀分布中生成当前神经元的权重，其中
d为每个神经元的输入数量。

##### 2.1.4.3 Xavier 初始化

该方法的基本思想是各层的激活值和梯度的方差在传播过程中保持一致，也叫做Glorot初始
化。在tf.keras中实现的方法有两种:

1. 正态化Xavier初始化:

Glorot 正态分布初始化器，也称为 Xavier 正态分布初始化器。它从以0为中心，标准差为 `stddev
=sqrt(2 /(fan_in + fan_out))`的正态分布中抽取样本，其中 `fan_in` 是输入神经元的个
数，`fan_out` 是输出的神经元个数。

实现方法为

```python
# 导入工具包
import tensorflow as tf
# 进行实例化
initializer = tf.keras.initializers.glorot_normal()
# 采样得到权重值
values = initializer(shape=(9,1))
# 打印结果
print(values)
```

输出结果为:

```
tf.Tensor(
[[ 0.15060258]
 [-0.16967624]
 [-0.00986955]
 [ 0.69665116]
 [-0.2782742 ]
 [ 0.33248395]
 [-0.25217363]
 [ 0.80073106]
 [ 0.4358515 ]], shape=(9, 1), dtype=float32)
```

2. 标准化Xavier初始化

Glorot 均匀分布初始化器，也称为 Xavier 均匀分布初始化器。它从[Himit，limit] 中的均匀分布中
抽取样本，其中 `limit` 是 `sqrt(6 / (fan_in + fan_out))`，其中 `fan_in` 是输入神经元的个数，`fan_out` 是输出的神经元个数。

```python
# 进行实例化
initializer = tf.keras.initializers.glorot_uniform()
# 采样得到权重值
values = initializer(shape=(9,1))
# 打印结果
print(values)
```

输出结果

```
tf.Tensor(
[[ 0.70924664]
 [ 0.36072648]
 [-0.31136808]
 [-0.30530545]
 [-0.16475093]
 [ 0.5317981 ]
 [ 0.23269916]
 [-0.40859896]
 [ 0.40286565]], shape=(9, 1), dtype=float32)
```



##### 2.1.4.4 He 初始化

he初始化，也称为Kaiming初始化，出自大神何恺明之手，它的基本思想是正向传播时，激活值的
方差保持不变;反向传播时，关于状态值的梯度的方差保持不变。在tf.keras中也有两种:

1. 正态化的he初始化

He 正态分布初始化是以0为中心，标准差为 stddev = sqrt(2 / fan_in)的截断正态分布中抽
取样本，其中 fan_in 是输入神经元的个数，在tf.keras中的实现方法为:

```python
# 进行实例化
initializer = tf.keras.initializers.he_normal()
# 采样得到权重值
values = initializer(shape=(9,1))
# 打印结果
print(values)
```

输出结果

```
tf.Tensor(
[[-0.30744317]
 [ 0.5207422 ]
 [ 0.60492384]
 [ 0.44051105]
 [ 0.13994461]
 [ 0.94229674]
 [ 0.33493984]
 [ 0.4326014 ]
 [ 0.40109786]], shape=(9, 1), dtype=float32)
```

2. 标准化的he初始化

He均匀方差缩放初始化器。它从[imit，limit] 中的均匀分布中抽取样本，其中 `limit`是
`sqrt(6 / fan_in)`，其中 `fan_in` 输入神经元的个数。实现为:

```python
# 进行实例化
initializer = tf.keras.initializers.he_uniform()
# 采样得到权重值
values = initializer(shape=(9,1))
# 打印结果
print(values)
```

输出结果

```
tf.Tensor(
[[-0.5082334 ]
 [-0.7525437 ]
 [-0.0021857 ]
 [ 0.23498237]
 [ 0.13910955]
 [ 0.62905586]
 [ 0.41731238]
 [-0.23065972]
 [ 0.53876853]], shape=(9, 1), dtype=float32)
```



#### 2.1.5 神经网络的搭建

搭建如下图所示的神经网络

![image-20240228081011802](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/7d6e29d16b8fe35198eaf72c5b277a33.png)

tf.Keras中构建模有两种方式，一种是通过Sequential构建，一种是通过Model类构建。前者是按-
定的顺序对层进行堆叠，而后者可以用来构建较复杂的网络模型。首先我们介绍下用来构建网络的全连接层:

```python
import tensorflow as tf

units = 4
tf.keras.layers.Dense(
    units, activation=None, use_bias=True, kernel_initializer='glorot_uniform',bias_initializer='zeros'
)
```

主要参数:

- units:当前层中包含的神经元个数
- Activation:激活函数，relu,sigmoid等
- use_bias: 是否使用偏置，默认使用偏置
- Kernel_initializer:权重的初始化方式，默认是Xavier初始化
- bias_initializer:偏置的初始化方式，默认为0

##### 2.1.5.1 通过 Sequential 构建

`Sequential()`提供一个层的列表，就能快速地建立一个神经网络模型，实现方法如下所示

```python
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# 定义一个Sequential模型，包含三层
model = keras.Sequential(
    [
        # 第一层，激活函数为relu，权重初始化为he_normal
        layers.Dense(3, activation='relu', kernel_initializer='he_normal', name='layer1', input_shape=(3, )),
        # 第二层 激活函数为relu，权重初始化为he_normal
        layers.Dense(2, activation='relu', kernel_initializer='he_normal', name='layer2'),
        # 第三层(输出层) 激活函数为sigmoid, 权重初始化为he_normal
        layers.Dense(2, activation='sigmoid', kernel_initializer='he_normal', name='layer3')
    ],
    name='my_sequential'
)
```

使用

```python
# 展示模型结果
model.summary()
```

输出

```
Model: "my_sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 layer1 (Dense)              (None, 3)                 12        
                                                                 
 layer2 (Dense)              (None, 2)                 8         
                                                                 
 layer3 (Dense)              (None, 2)                 6         
                                                                 
=================================================================
Total params: 26 (104.00 Byte)
Trainable params: 26 (104.00 Byte)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
```



##### 2.1.5.2 使用 function API 构建

```python
import tensorflow as tf

# 定义模型的输入
inputs = tf.keras.Input(shape=(3,), name='input')
# 第一层 激活函数为relu 其他默认
x = tf.keras.layers.Dense(3, activation='relu', name='layer1')(inputs)
# 第二层
x = tf.keras.layers.Dense(2, activation='sigmoid', name='layer2')(x)
# 第三层(输出层)
outputs = tf.keras.layers.Dense(2, activation='sigmoid', name='layer3')(x)
# 使用model构建模型
model = tf.keras.Model(inputs=inputs, outputs=outputs, name='my_model')
model.summary()
```

输出

```
Model: "my_model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input (InputLayer)          [(None, 3)]               0         
                                                                 
 layer1 (Dense)              (None, 3)                 12        
                                                                 
 layer2 (Dense)              (None, 2)                 8         
                                                                 
 layer3 (Dense)              (None, 2)                 6         
                                                                 
=================================================================
Total params: 26 (104.00 Byte)
Trainable params: 26 (104.00 Byte)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
```

##### 2.1.5.3 通过 model 的子类构建

通过model的子类构建模型，此时需要在`__init__`中定义神经网络的层，在`call`方法中定义网络的前向传播过程，实现方法如下

```python
import tensorflow as tf


# 定义model的子类
class MyModel(tf.keras.Model):
    # 在__init 方法中定义网络的层结构
    def __init__(self):
        super(MyModel, self).__init__()
        # 第一层
        self.layers1 = tf.keras.layers.Dense(3, activation='relu', kernel_initializer='he_normal', name='layer1',
                                             input_shape=(3,))
        # 第二层
        self.layers2 = tf.keras.layers.Dense(2, activation='relu', kernel_initializer='he_normal', name='layer2')
        # 第三层
        self.layers3 = tf.keras.layers.Dense(2, activation='sigmoid', kernel_initializer='he_normal', name='layer3')

    # 在call方法中完成前向传播
    def call(self, inputs):
        x = self.layers1(inputs)
        x = self.layers2(x)
        return self.layers3(x)


# 实例化模型
model = MyModel()
# 设置一个输入，调用模型
x = tf.ones((1, 3))
y = model(x)
model.summary()
```

输出

```
Model: "my_model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 layer1 (Dense)              multiple                  12        
                                                                 
 layer2 (Dense)              multiple                  8         
                                                                 
 layer3 (Dense)              multiple                  6         
                                                                 
=================================================================
Total params: 26 (104.00 Byte)
Trainable params: 26 (104.00 Byte)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
```



#### 2.1.6 神经网络的优缺点

1. 优点

   - 精度高，性能优于其他的机器学习方法，甚至在某些领域超过了人类

   - 可以近似任意的非线性函数

   - 随之计算机硬件的发展，近年来在学界和业界受到了热捧，有大量的框架和库可供调用

2. 缺点
   - 黑箱，很难解释模型是怎么工作的
   - 训练时间长，需要大量的计算力
   - 网络结构复杂，需要调整超参数
   - 小数据集上表现不佳，容易发生过拟合



### 2.2 损失函数

![image-20240228092603305](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/5455d59f9a1905eaf45c250f00a2d4ba.png)

在深度学习中,损失函数是用来衡量模型参数的质量的函数,衡量的方式是比较网络输出和真实输出
的差异，损失函数在不同的文献中名称是不一样的，主要有以下几种命名方式:

![image-20240228092713579](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/60f0cd146f0edcebc34069a11496fe52.png)



#### 2.2.1 分类任务

在深度学习的分类任务中使用最多的是交叉损失函数

##### 2.2.1.1 多分类任务

在多分类任务通常使用softmax将logits转换为概率的形式，所以多分类的交叉熵损失也叫做
softmax损失，它的计算方法是:
$$
\iota=-\sum\limits_{ i=1 }^{n}y_{i}\log(S(f_{\theta}(X_{i}))) 
$$
- labels(one-hot): $y_{i}$
- SoftMax: $S$

其中，y是样本x属于某一个类别的真实概率，而f(x)是样本属于某一类别的预测分数，S是softmax
函数，L用来衡量p,q之间差异性的损失结果。

![image-20240228111655746](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/03d89850d3ca9e08e553796483200d1e.png)

上图中的交叉熵损失为
$$
-(0log(0.10)+1log(0.7)+0log(0.2))=-log0.7
$$
从概率角度理解，我们的目的是最小化正确类别所对应的预测概率的对数的负值，如下图所示:

![image-20240228112118817](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/d116c1233ffcb40d1366f5bb857156da.png)

在tf.keras中使用CategoricalCrossentropy实现

```python
import tensorflow as tf

# 设置真实值和预测值
y_true = [[0, 1, 0], [0, 0, 1]]
y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]
# 实例化交叉熵损失
cce = tf.keras.losses.CategoricalCrossentropy()
# 计算损失结果
cce(y_true, y_pred).numpy()
```

结果

```
1.1769392
```



##### 2.2.1.2 二分类任务

在处理二分类任务时，我们不在使用softmax激活函数，而是使用sigmoid激活函数，那损失函数
也相应的进行调整，使用二分类的交叉熵损失函数:
$$
L=-y\log \bar{y}-(1-y)\log(1-\bar{y}) 
$$
tf.keras 中实现时使用 `BinaryCrossentropy()`，如下所示

```python
import tensorflow as tf
# 设置真实值和预测值
y_true = [[0],[1]]
y_pred = [[0.4], [0.6]]
# 实例化二分类交叉熵损失
bce = tf.keras.losses.BinaryCrossentropy()
# 计算损失结果
bce(y_true, y_pred).numpy()
```

结果

```
0.5108254
```



#### 2.2.2 回归任务

回归任务中常用的损失函数有以下几种

##### 2.2.2.1 MAE 损失 

Mean absolute loss(MAE)也被称为L1Loss，是以绝对误差作为距离
$$
\iota = \frac{1}{n}\sum\limits_{ i=1 }^{n}\left| y_{i}-f_{\theta}(x_{i}) \right|
$$
曲线如下图所示:

![image-20240228144657229](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/59101daea1b5dcdd44d0326426e93399.png)

特点是:由于L1loss具有稀疏性，为了惩罚较大的值，因此常常将其作为正则项添加到其他loss
中作为约束。L1loss的最大问题是梯度在零点不平滑，导致会跳过极小值。

在tf.keras中使用MeanAbsoluteError实现，如下所示

```python
import tensorflow as tf
y_true = [[0.],[0.]]
y_pred = [[1.],[1.]]
mae = tf.keras.losses.MeanAbsoluteError()
mae(y_true, y_pred).numpy()
```

输出

```
1.0
```



##### 2.2.2.2 MSE 损失

Mean SquaredLoss/Quadratic Loss(MSE loss)也被称为L2 loss，或欧氏距离，它以误差的平方和作为距离


$$
\iota = \frac{1}{n}\sum\limits_{ i=1 }^{n}(y_{i}-f_{\theta}(x_{i}))^2
$$

曲线如下图所示

![image-20240228145219326](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/3bb32874e35580245b89ee404726318b.png)

特点是: L2loss也常常作为正则项。当预测值与目标值相差很大时,梯度容易爆炸
在tf.keras中通过MeanSquaredError实现:

```python
import tensorflow as tf
y_true = [[0.],[1.]]
y_pred = [[1.],[1.]]
mse = tf.keras.losses.MeanSquaredError()
mse(y_true, y_pred).numpy()
```

输出

```
0.5
```

##### 2.2.2.3 smooth L1损失
$$
smooth_{{L_{1}}}(x)=
\left\{
\begin{array}{ll}
    0.5x^{2} & if \left| t \right| < 1 \\
    \left| x \right|  & otherwise \\
\end{array}
\right.
$$

其中:x=f(x)-y 为真实值和预测值的差值。

![image-20240228145604913](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/1832c6943e5faacecfc7a4d6e83366d4.png)

从上图中可以看出，该函数实际上就是一个分段函数，在[1,1]之间实际上就是L2损失，这样解决
了L1的不光滑问题，在[1,1]区间外，实际上就是L1损失，这样就解决了离群点梯度爆炸的问题。通常在目标检测中使用该损失函数

在tf.keras中使用Huber计算该损失，如下所示

```python
import tensorflow as tf
y_true = [[0],[1]]
y_pred = [[0.6], [0.4]]
h = tf.keras.losses.Huber()
h(y_true, y_pred).numpy()
```

结果

```
0.18
```



### 2.3 深度学习的优化方法

#### 2.3.1 梯度下降算法

梯度下降法简单来说就是一种寻找使损失函数最小化的方法。大家在机器学习阶段已经学过该算
法，所以我们在这里就简单的回顾下，从数学上的角度来看，梯度的方向是函数增长速度最快的方向，那么梯度的反方向就是函数减少最快的方向，所以有:
$$
W^{new}_{ij}=W^{old}_{ij}-\eta\frac{\partial E}{\partial W_{ij}}
$$
其中，n是学习率，如果学习率太小，那么每次训练之后得到的效果都太小，增大训练的时间成
本。如果，学习率太大，那就有可能直接跳过最优解，进入无限的训练中。解决的方法就是，学习率也需要随着训练的进行而变化。

![image-20240228160447454](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/f3326a30f1baf3e9e61a2d7dc9952ab2.png)

 在上图中我们展示了一维和多维的损失函数，损失函数呈碗状。在训练过程中损失函数对权重的偏导数就是损失函数在该位置点的梯度。我们可以看到，沿着负梯度方向移动，就可以到达损失函数底部，从而使损失函数最小化。这种利用损失函数的梯度迭代地寻找局部最小值的过程就是梯度下降的过程。

根据在进行迭代时使用的样本量，将梯度下降算法分为以下三类

| 梯度下降算法          | 定义                                                         | 缺点                               | 优点                                       |
| --------------------- | ------------------------------------------------------------ | ---------------------------------- | ------------------------------------------ |
| BGD (批量梯度下降)    | 每次迭代时需要计算每个样本上损失函数的梯度并求和             | 计算量大、迭代速度慢               | 全局最优化                                 |
| SGD (随机梯度下)      | 每次迭代时只 采集一个样本，计算这个样本损失函数的梯度并更新参数 | 准确度下降、存在噪音、非全局最优化 | 训练速度快、支持在线学习                   |
| MBGD (小批量梯度下降) | 每次迭代时，我们随机选取一小部分训练样本来计算梯度 并更新参数 | 准确度不如BG、D非全局最优解        | 计算小批量数据的梯度更加高效、支持在线学习 |

实际中使用较多的是小批量的梯度下降算法，在tf.keras中通过以下方法实现

```python
tf.keras.optimizers.SGD(
    learning_rate=0.01, momentum=0.0, nesterov=False, name='SGD'
)
```

例子

```python
import tensorflow as tf

# 实例化优化方法：SGD
opt = tf.keras.optimizers.SGD(learning_rate=0.1)
# 定义要调整的参数
var = tf.Variable(1.0)
# 定义损失函数：无参但有返回值
loss = lambda: (var ** 2) / 2.0
# 计算梯度，并对参数进行更新，步长为 `- learning_rate * grad`
opt.minimize(loss, [var])
# 展示参数更新结果
var.numpy()
```

结果

```
0.9
```

在进行模型训练时，有三个基础的概念:

| 名词        | 定义                                               |
| --------- | ------------------------------------------------ |
| Epoch     | 使用训练集的全部数据对横型进行一次完整训练，被称之为“一代训练”                 |
| Batch     | 使用训练集中的一小部分样本对模型权重进行一次反向传播的参数更新，这一小部分样本被称为"一批数据" |
| Iteration | 使用一个 Batch 数据对模型进行一次参数更新的过程，被称之为"一次训练"           |

实际上，梯度下降的几种方式的根本区别就在于上面公式中的 Batch Size不同，如下表所示:

| 梯度下降方式     | Training Set Size | Batch Size | Number of Batches |
| ---------- | ----------------- | ---------- | ----------------- |
| BGD        | N                 | N          | 1                 |
| SGD        | N                 | 1          | N                 |
| Mini-Batch | N                 | B          | N/B+1             |

注:上表中 Mini-Batch 的 Batch 个数为 N/B+1是针对未整除的情况。整除则是 N/B

假设数据集有50000个训练样本，现在选择 Batch Size = 256 对模型进行训练

- 每个 Epoch 要训练的图片数量: 50000
- 训练集具有的 Batch 个数: 50000/256+1=196
- 每个Epoch 具有的lteration 个数:196
- 10个Epoch 具有的lteration 个数:1960



#### 2.3.2 反向传播算法(BP 算法)

利用反向传播算法对神经网络进行训练。该方法与梯度下降算法相结合，对网络中所有权重计算损失函数的梯度，并利用梯度值来更新权值以最小化损失函数。在介绍BP算法前，我们先看下前向传播与链式法则的内容。

##### 2.3.2.1 前向传播和反向传播

前向传播指的是数据输入的神经网络中，逐层向前传输，一直到运算到输出层为止

![image-20240228171204430](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/b14bf76f8527622a55c0483355429619.png)

在网络的训练过程中经过前向传播后得到的最终结果跟训练样本的真实值总是存在一定误差，这个误差便是损失函数。想要减小这个误差，就用损失函数ERROR，从后往前，依次求各个参数的偏导，这就是反向传播 (Back Propagation)

##### 2.3.2.2 链式法则

反向传播算法是利用链式法则进行梯度求解及权重更新的。对于复杂的复合函数，我们将其拆分为一系列的加减乘除或指数，对数，三角函数等初等函数，通过链式法则完成复合函数的求导。为简单起见，这里以一个神经网络中常见的复合函数的例子来说明 这个过程令复合函数 f(x;w,b)为
$$
f(x;w,b)=\frac{1}{exp(-(wx+b))+1}
$$
其中x是输入数据，w是权重，b是偏置。我们可以将该复合函数分解为:

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/fb0f57576fde877cee7060b5f3e668a8.png)

并图像化表示

  ![image-20240228171616128](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/606a59e84cbdde76fc4d855d0099a899.png)

整个复合函数 (x; wb)关于参数 w和b导数可以通过(x;w,b) 与参数和b之间路径上所有的导数连乘来得到，即:

![image-20240228171637451](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/3a47ed70be71e3cac36595fd9734dc96.png)

以w为例，当x=1,w=0,b= 时，可以得到:

![image-20240228171919379](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/c746dca1bdd2ba0993c042cda396eb81.png)



##### 2.3.2.3 反向传播算法



#### 2.3.3 梯度下降优化方法

梯度下降算法在进行网络训练时，会遇到鞍点，局部极小值这些问题，那我们怎么改进SGD呢?在
这里我们介绍几个比较常用的

![image-20240228172320687](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/c341634d7f9e21c026c8cbfa5111cd1c.png)

##### 2.3.3.1 动量算法

动量算法主要解决鞍点问题。在介绍动量法之前，我们先来看下指数加权平均数的计算方法。

**指数加权评价**

假设给定一个序列，例如北京一年每天的气温值，图中蓝色的点代表真实数据,

![image-20240228173654808](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/8772f65537713c5b9209281efc49b255.png)

这时温度值波动比较大，那我们就使用加权平均值来进行平滑，如下图红线就是平滑后的结果:

![image-20240228173735504](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/2dfe6aacc0de5138469d91fd277c610c.png)

计算方法如下所示
$$
S_t=
\left\{
\begin{array}{ll}
    Y_1 & t=1 \\
    \beta S_{t-1+(1-\beta)Y_t} &  t>1\\
\end{array}
\right.
$$
其中Yt为t时刻时的真实值，St为t加权平均后的值，B为权重值。红线即是指数加权平均后的结
果。

上图中B设为0.9，那么指数加权平均的计算结果为
$$
\begin{align} \\
S_1&=Y_1 \\
S_2&= 0.9S_1+0.1Y_2 \\
... \\
S_{99}&=0.9S_{98}+0.1Y_{99} \\
...
&\end{align}
$$
那么第100天的结果就可以表示为
$$
S_{100}=0.1Y_{100}+0.1
$$
**动量梯度下降算法**
动量梯度下降 (Gradient Descent with Momentum）计算梯度的指数加权平均数，并利用该值来更新参数值。动量梯度下降法的整个过程为，其中 $\beta$ 通常设置为 0.9:
$$
\begin{align}
S_{dW}[l]&=\beta S_{dW}[l]+(1-\beta)dW^{[l]} \\
S_{db}[l]&=\beta S_{db}[l]+(1-\beta)db^{l} \\
W^{[l]}:&=b^{[l]}-\alpha S_{db}[l] \\
b^{[l]}:&=b^{[l]}-\alpha S_{db}[l]
\end{align}
$$
与原始的梯度下降算法相比，它的下降趋势更加平滑。
![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/5fc17df75c0e475d9bb0ec8011c00f53.png)
在 tf.keras 中使用 Momentum 算法仍使用功能 SGD 方法，但要设置 momentum 参数，实现过程如下：
```python
import tensorflow as tf  
  
# 实例化优化方法：SGD 指定参数beta=0.9  
opt = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)  
# 定义要调整的参数，初始值  
var = tf.Variable(1.0)  
val0 = var.value()  
# 定义损失函数  
loss = lambda: (var ** 2) / 2.0  
# 第一次更新：计算梯度，并对参数进行更新，步长为`- learning_rate * grad`  
opt.minimize(loss, [var])  
val1 = var.value()  
# 第二次更新：计算梯度，并对参数进行更新，因为加入了momentum，步长会增加  
opt.minimize(loss, [var])  
val2 = var.value()  
# 打印两次更新的步长  
print("第一次更新步长={}".format((val0 - val1).numpy()))  
print("第二次更新步长={}".format((val1 - val2).numpy()))
```
输出
```
第一次更新步长=0.10000002384185791
第二次更新步长=0.18000000715255737
```
另外还有一种动量算法 Nesterov accelerated gradient (NAG)，使用了根据动量项**预先估计**的参
数，在 Momentum 的基础上进一步加快收敛，提高响应性，该算法实现依然使用 SGD 方法，要设
置 nesterov 设置为 true.

##### 2.3.3.2 AdaGrad
AdaGrad 算法会使用**一个小批量随机梯度**g_t 按元素平方的累加变量 st。在时间步 0，AdaGrad
将 s0 中每个元素初始化为 0。在时间步 t，首先将小批量随机梯度 gt 按元素平方后累加到变量 st:
$$
s_{t-1}+g_{t} ⊙ g_{t} \to s_{t}
$$
其中 ⊙ 是按元素相乘。接着，我们将目标函数自变量中每个元素的学习率通过按元素运算重新调整
$$
w_{t-1}-\frac{\alpha}{\sqrt{ s_{t} + \epsilon }} ⊙ g_{t} \to w_{t}
$$
其中 a 是学习率，e 是为了维持数值稳定性而添加的常数，如 $10^{-6}$。这里开方、除法和乘法的运算都是按元素运算的。这些按元素运算使得目标函数自变量中每个元素都分别拥有自己的学习率

在 tf.keras 中实现方法是：
```python
opt = tf.keras.optimizers.Adagrad(  
    learning_rate=0.1, initial_accumulator_value=0.1, epsilon=1e-07  
)
```
例子
```python
import tensorflow as tf  
# 实例化优化方法: SGD  
opt = tf.keras.optimizers.Adagrad(  
    learning_rate=0.1, initial_accumulator_value=0.1, epsilon=1e-07  
)  
# 定义要调整的参数  
var = tf.Variable(1.0)  
# 定义损失函数：无参但有返回值  
def loss(): return (var ** 2) /2.0  
# 计算梯度，并对参数进行更新  
opt.minimize(loss, [var])  
# 展示参数更新结果  
var.numpy()
```
输出
```
0.9046537
```

##### 2.3.3.3 RMSprop
AdaGrad 算法在迭代后期由于学习率过小, 能较难找到最优解。为了解决这一问题，RMSProp 算法对 AdaGrad 算法做了一点小小的修改。

不同于 AdaGrad 算法里状态变量 st 是截至时间步 t 所有小批量随机梯度 qt 按元素平方和 RMSProp(RootMean Square Prop)算法将这些梯度按元素平方做指数加权移动平均

$$
\begin{align}
s_{dw}&=\beta s_{dw}+(1-\beta)(dw)^{2} \\
s_{dw}&=\beta s_{db}+(1-\beta)(db)^{2}  \\
w:&=w-\frac{a}{\sqrt{ s_{dw} + \epsilon }}dw \\ \\
b:&=b-\frac{a}{\sqrt{ s_{db} + \epsilon }}db \\
\end{align}
$$

其中 $\epsilon$ 是一样为了维持数值稳定一个常数。最终自变量每个元素的学习率在迭代过程中就不再一直降低。RMSProp 有助于减少抵达最小值路径上的摆动，并允许使用一个更大的学习率 a，从而加快算法学习速度。

在 tf. keras 中实现时，使用的方法是:
```python
opt = tf.keras.optimizers.RMSprop(learning_rate=0.1)
```

例子
```python
import tensorflow as tf  
  
# 实例化优化方法RMSprop  
opt = tf.keras.optimizers.RMSprop(learning_rate=0.1)  
# 定义要调整的参数  
var = tf.Variable(1.0)  
  
  
# 定义损失函数  
def loss(): return (var ** 2) / 2.0  
opt.minimize(loss, [var])  
var.numpy()
```
输出
```
0.6837723
```

##### 2.3.3.4 Adam
Adam 优化算法 (Adaptive Moment Estimation 自适应矩估计) 将 Mnntum 和 RMSProp 算法结合在一起。Adam 算法在 RMSProp 算法基础上对小批量随机梯度也做了指数加权移动平均。

假设用每一个 mini-batch 计算 dW、db，第 t 次迭代时:

$$
\begin{align}
v_{dW} &= \beta_{1}dW+(1-\beta_{1})dW \\
v_{db} &= \beta_{1}v_{db}+(1-\beta_{1})db \\
v_{dW}^{corrected}[l] &= \frac{v_{dW}[l]}{1-{(\beta_{1})^{t}}} \\
s_{dW} &= \beta_{2}s_{dW}+(1-\beta_{2})(dW)^{2} \\
s_{db} &= \beta_{2}s_{db}+(1-\beta_{2})(db)^{2} \\
s_{dW}^{corrected}[l] &= \frac{s_{dW}[l]}{1-(\beta_{2})^{t}}
\end{align}
$$

其中 I 为某一层，t 为移动平均第次的值

Adam 算法的参数更新:

$$
\begin{align}
W:&=W-\alpha \frac{ v_{dW}^{corrected}}{\sqrt{ s_{dW}^{corrected} + \epsilon }} \\
b:&=b-\alpha \frac{ v_{db}^{corrected}}{\sqrt{ s_{dW}^{corrected} + \epsilon }} \\
\end{align}
$$

建议的参数设置的值:
- 学习率 $\alpha$: 需要尝试一系列的值，来寻找比较合适的
- $\beta_{1}$: 常用的缺省值为 0.9
- $\beta_{2}$: 建议为 0.999
- $\epsilon$: 默认值 1e-8

例子
```python
import tensorflow as tf  
  
# 实例化优化方法Adam  
opt = tf.keras.optimizers.Adam(learning_rate=0.1)  
# 定义要调整的参数  
var = tf.Variable(1.0)  
  
  
# 定义损失函数  
def loss(): return (var ** 2) / 2.0  
  
  
opt.minimize(loss, [var])  
var.numpy()
```
输出
```
0.900001
```

#### 2.3.4 学习率退火
在训练神经网络时，一般情况下学习率都会随着训练而变化，这主要是由于，在神经网络训练的后期，如果学习率过高，会造成 loss 的振荡，但是如果学习率减小的过快，又会造成收敛变慢的情况。

##### 2.3.4.1 分段常数衰减
分段常数衰减是在事先定义好的训练次数区间上，设置不同的学习率常数。刚开始学习率大一些之后越来越小，区间的设置需要根据样本量调整，一般样本量越大区间间隔应该越小。

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/2b154f7582f1b64e7bb92c276eef34ea.png)

例子

```python
# 设置的分段更新的step值  
bundaries = [100000, 110000]  
# 不同的step对应的学习率  
values = [1.0, 0.5 ,0.1]  
# 实例化进行学习的更新  
learning_rate_fn = tf.keras.optimizers.schedules.PiecewiseConstantDecay(bundaries, values)
```

##### 2.3.4.2 指数衰减
指数衰减可以用如下的数学公式表示

$$
a=a_{0}e^{-kt}
$$

其中，t 表示迭代次数，$a_{0}$, k 是超参数

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/c49648264a3b1cfcd0cab1b2c175b5f4.png)

##### 2.3.4.3 1/t 衰减
1/t 衰减可以用如下的数学公式表示

$$
a=\frac{a_{0}}{1+kt}
$$

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/a4978b0df702a34d9af202c457221f04.png)

### 2.4 深度学习正则化

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/912f2e2fc9591b0c44558b07cd432e47.png)

在设计机器学习算法时不仅要求在训练集上误差小，而且希望在新样本上的泛化能力强。许多机器学习算法都采用相关的策略来减小测试误差，这些策略被统称为正则化。因为神经网络的强大的表示能力经常遇到过拟合，所以需要使用不同形式的正划化策略。

正则化通过对算法的修改来减少泛化误差，目前在深度学习中使用较多的策略有参数范数惩罚，提前终止，DropOut 等，接下来我们对其进行详细的介绍。


#### 2.4.1 L1 与 L2 正则化

L1 和 L2 是最常见的正则化方法。它们在损失函数 (cost function)中增加一个正则项，由于添加了这个正则化项，权重矩阵的值减小，因为它假定具有更小权重矩阵的神经网络导致更简单的模型。因此，它也会在一定程度上减少过拟合。然而，这个正则化项在 L1 和 L2 中是不同的。

1. L2 正则化

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/ffbeacbfffc03892d19b461f056b94b0.png)

这里的入是正则化参数，它是一个需要优化的超参数。L 2 正则化又称为权重衰减，因为其导致权重趋向于 0 (但不全是 0)

2. L1 正则化

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/f6f0a33efa5bc9deb559dc2355b7e965.png)

这里，我们惩罚权重矩阵的绝对值。其中，入为正则化参数，是超参数，不同于 L2，权重值可能被减少到 0. 因此，L1 对于压缩模型很有用。其它情况下，一般选择优先选择 L2 正则化。

#### 2.4.2 Dropout 正则化

dropout 是在深度学习领域最常用的正则化技术。Dropout 的原理很简单: 假设我们的神经网络结构如下所示，在每个迭代过程中，随机选择某些节点，并且删除前向和后向连接。

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/836328b705ab0b668c5fedfebba6f994.png)

因此，每个迭代过程都会有不同的节点组合，从而导致不同的输出，这可以看成机器学习中的集成方法 (ensemble technique)。集成模型一般优于单一模型，因为它们可以捕获更多的随机性。相似地，dropout 使得神经网络模型优于正常的模型

#### 2.4.3 提前停止

提前停止 (earlystopping, 是将-部分训练集作为验证集 (validation set)。当验证集的性能越来越差时或者性能不再提升，则立即停止对该模型的训练。这被称为提前停止。

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/68fe2b8ef0a898e1a947bcb910a013b0.png)

在上图中，在虚线处停止模型的训练，此时模型开始在训练数据上过拟合


#### 2.4.4 批标准化

批标准化 (BN 层, Batch Normalization)是 2015 年提出的一种方法，在进行深度网络训练时，大多会采取这种算法，与全连接层一样，BN 层也是属于网络中的一层。

BN 层是针对单个神经元进行，利用网络训练时一个 mini-batch 的数据来计算该神经元 xi 的均值和方差, 归一化后并重构，因而称为 Batch Normalization。在每一层输入之前，将数据进行 BN，然后再送入后续网络中进行学习:

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/52493e90cb3aaa1c0c6656715b0102f8.png)

首先我们对某一批次的数据的神经元的输出进行标准化

$$
\begin{align}
\mu&=\frac{1}{m}\sum_{i}z^i \\
\sigma^2&=\frac{1}{m}\sum_{i}(z_{i}-\mu)^2 \\
z_{norm}^{i}&=\frac{{z^i-\mu}}{\sqrt{ \sigma^{2} + \epsilon }} \\
\end{align}
$$

然后在使用变换重构，引入了可学习参数 Y、B，如果各隐藏层的输入均值在靠近0的区域，即处于激活函数的线性区域，不利于训练非线性神经网络，从而得到效果较差的模型。因此，需要用 v 和 B 对标准化后的结果做进一步处理

$$
\bar{z}^i=\gamma z_{morm}^{i}+ \beta
$$

这就是 BN 层最后的结果。整体流程如下图所示:

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/d3a0dced0abd5dbf44ba239342fb33fd.png)


###  2.5 神经网络案例

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/17e1da970913e81daeecd029581c46f5.png)

使用手写数字的 MNIST 数据集如上图所示，该数据集包含60,000个用于训练的样本和10,000个用于测试的样本，图像是固定大小 (28x28像素)，其值为0到255。

整个案例的实现流程是:
- 数据加载
- 数据处理
- 模型构建
- 模型训练
- 模型测试
- 模型保存

首先导入所需的工具包

```python
import numpy as np  
import matplotlib.pyplot as plt  
  
plt.rcParams['figure.figsize'] = (7, 7)  
import tensorflow as tf  
# 数据集  
from tensorflow.keras.datasets import mnist  
# 构建序列模型  
from tensorflow.keras.models import Sequential  
# 导入需要的层  
from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization  
# 导入辅助工具包  
from tensorflow.keras import utils  
# 正则化  
from tensorflow.keras import regularizers
```

#### 2.5.1 数据加载

```python
# 类别总数  
nb_classes = 10  
# 加载数据集  
(X_train, y_train), (X_test, y_test) = mnist.load_data()  
# 打印数据集信息  
print("训练样本初始维度", X_train.shape)  
print("训练样本目标值初始维度", y_train.shape)
```

输出

```
训练样本初始维度 (60000, 28, 28)
训练样本目标值初始维度 (60000,)
```

数据展示

```python
# 数据展示  
for i in range(9):  
    plt.subplot(3, 3, i + 1)  
    # 以灰度图显示，不进行插值  
    plt.imshow(X_train[i], cmap='gray', interpolation='none')  
    # 设置图片的标题：对应的类别  
    plt.title("num{}".format(y_train[i]))
```

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/72714c3e600eac08bdd176dce5a90966.png)


#### 2.5.2 数据处理

神经网络中的每个训练样本是一个向量，因此需要对输入进行重塑，使每个28x28的图像成为一个的784维向量。另外，将输入数据进行归一化处理，从0-255调整到0-1。

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/152840bccb8f4410e0c2a7055ab5219f.png)

```python
# 调整数据维度：每个数字转换成一个向量  
X_train = X_train.reshape(60000, 784)  
X_test = X_test.reshape(10000, 784)  
# 格式转换  
X_train = X_train.astype('float32')  
X_test = X_test.astype('float32')  
# 归一化  
X_train /= 255  
X_test /= 255  
# 维度调整后的结果  
print("训练集：", X_train.shape)  
print("测试集：", X_test.shape)
```

```
训练集： (60000, 784)
测试集： (10000, 784)
```

另外对于目标值我们也需要进行处理，将其转换为热编码的形式:

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/119b2ebfe4072813b4ca33a2519d6e61.png)

```python
# 将目标值转换为热编码的形式  
Y_train = utils.to_categorical(y_train, nb_classes)  
y_test = utils.to_categorical(y_test, nb_classes)
```

#### 2.5.3 模型构建

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/2ad2aa00a259a1e82969e89c0c1e7723.png)

```python
# 使用序列模型来构建模型  
model = Sequential()  
# 全连接层，共512个神经元，输入维度大小为784  
model.add(Dense(512, input_shape=(784,)))  
# 激活函数使用relu  
model.add(Activation('relu'))  
# 使用正则化方法drouout  
model.add(Dropout(0.2))  
# 全连接层，共512个神经元，并加入L2正则化  
model.add(Dense(512, kernel_regularizer=regularizers.l2(0.001)))  
# BN层  
model.add(BatchNormalization())  
# 激活函数  
model.add(Activation('relu'))  
model.add(Dropout(0.2))  
# 全连接层  
model.add(Dense(10))  
# softmax将神经网络输出的score转换为概率值  
model.add(Activation('softmax'))
model.summary()
```

```
Model: "sequential_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense_3 (Dense)             (None, 512)               401920    
                                                                 
 activation_3 (Activation)   (None, 512)               0         
                                                                 
 dropout_2 (Dropout)         (None, 512)               0         
                                                                 
 dense_4 (Dense)             (None, 512)               262656    
                                                                 
 batch_normalization_1 (Bat  (None, 512)               2048      
 chNormalization)                                                
                                                                 
 activation_4 (Activation)   (None, 512)               0         
                                                                 
 dropout_3 (Dropout)         (None, 512)               0         
                                                                 
 dense_5 (Dense)             (None, 10)                5130      
                                                                 
 activation_5 (Activation)   (None, 10)                0         
                                                                 
=================================================================
Total params: 671754 (2.56 MB)
Trainable params: 670730 (2.56 MB)
Non-trainable params: 1024 (4.00 KB)
_________________________________________________________________
```

#### 2.5.4 模型编译

设置模型训练使用的损失函数交叉熵损失和优化方法 adam，损失函数用来衡量预测值与真实值之间的差异，优化器用来使用损失函数达到最优:
```python
# 模型编译，指明损失函数和优化器，评估指标  
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
```

#### 2.5.5 模型训练

```python
# batch_size 是每次送入模型的样本个数，epochs是所有样本的迭代次数，并指明验证数据集  
history = model.fit(X_train, Y_train, batch_size=128, epochs=4, verbose=1, validation_data=(X_test, y_test))
```

训练过程

```
Epoch 1/4
469/469 [==============================] - 6s 12ms/step - loss: 0.1210 - accuracy: 0.9794 - val_loss: 0.1362 - val_accuracy: 0.9748
Epoch 2/4
469/469 [==============================] - 6s 12ms/step - loss: 0.1145 - accuracy: 0.9805 - val_loss: 0.1251 - val_accuracy: 0.9772
Epoch 3/4
469/469 [==============================] - 6s 12ms/step - loss: 0.1102 - accuracy: 0.9822 - val_loss: 0.1359 - val_accuracy: 0.9744
Epoch 4/4
469/469 [==============================] - 6s 12ms/step - loss: 0.1013 - accuracy: 0.9837 - val_loss: 0.1155 - val_accuracy: 0.9795
```

损失曲线

```python
# 绘制损失函数的变化曲线  
plt.figure()  
# 训练集损失函数变换  
plt.plot(history.history['loss'], label='train_loss')  
# 验证集损失函数变化  
plt.plot(history.history['val_loss'], label='val_loss')  
plt.legend()  
plt.grid()
```

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/5d753fde3d694ce3ed1262abf3a7d821.png)

准确率

```python
# 准确率  
plt.figure()  
plt.plot(history.history['accuracy'], label='train')  
plt.plot(history.history['val_accuracy'], label='val')  
plt.legend()  
plt.grid()
```

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/b83d87a0b484bef33b2c2a4ff0223136.png)

另外可通过 tensorboard 监控训练过程，这时我们指定回调函数
```python
# 添加tensorboard观察  
tensorboard = tf.keras.callbacks.TensorBoard(log_dir='./graph', histogram_freq=1, write_graph=True, write_images=True)
```

再进行训练
```python
# 再进行训练  
history = model.fit(X_train, Y_train, batch_size=128, epochs=4, verbose=1, callbacks=[tensorboard],  
                    validation_data=(X_test, y_test))
```

打开终端
```bash
# 指定存在文件的目录，打开下面命令
tensorboard --logdir="./graph"
```

打开http://localhost:6006/查看训练详情

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/221b32fb96a6f8db8fdc5a5cae03c73f.png)

#### 2.5.6 模型测试

```python
# 模型测试  
score = model.evaluate(X_test, y_test, verbose=1)  
# 打印结果  
print("测试集准确率:", score)
```

```
313/313 [==============================] - 1s 2ms/step - loss: 0.1187 - accuracy: 0.9802
测试集准确率: [0.11868521571159363, 0.9801999926567078]
```

#### 2.5.7 模型保存

```python
# 保存模型架构与权重在h5文件中  
model.save('my_model.h5')  
# 加载模型：包括架构和对应的权重  
model = tf.keras.models.load_model('my_model.h5')
```

### 2.6 卷积神经网络 CNN

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/a4fb737809cbabe671ac9c111962ef6e.png)

利用全连接神经网络对图像进行处理存在以下两个问题

1. **需要处理的数据量大，效率低**

假如我们处理一张 1000x1000 像素的图片，参数量如下
1000x1000x3=3,000,000

这么大量的数据处理起来是非常消耗资源的

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/55e78c72cbb9400ba0f2dec299550b37.png)

2. **图像在维度调整的过程中很难保留原有的特征，导致图像处理的准确率不高**

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/337f8eb998db30b475ac42d1aeb92eb8.png)

假如有圆形是1，没有圆形是0，那么圆形的位置不同就会产生完全不同的数据表达。但是从图像的角度来看，图像的内容 (本质)、并没有发生变化，只是位置发生了变化。所以当我们移动图像中的物体，用全连接升降得到的结果会差异很大，这是不符合图像处理的要求的。

#### 2.6.1 CNN 网络的构成

CNN 网络受人类视觉神经系统的启发，人类的视觉原理: 从原始信号摄入开始 (瞳孔摄入像素Pixels)，接着做初步处理 (大脑皮层某些细胞发现边缘和方向)，然后抽象 (大脑判定，眼前的物体的形状，是圆形的)，然后进一步抽象 (大脑进一步判定该物体是只人脸) 。下面是人脑进行人脸识别的一个示例:

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/6649268803950c92d8744a915d9f3c4b.png)

CNN 网络主要有三部分构成: 卷积层、池化层和全连接层构成，其中卷积层负责提取图像中的局部特征; 池化层用来大幅降低参数量级 (降维); 全连接层类似人工神经网络的部分，用来输出想要的结果。

 ![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/2cd23c788078b292dc332b7d82c767d8.png)

整个 CNN 网络结构如下图所示:

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/87431a9a8dd05c92f1aebb557f075ad5.png)


#### 2.6.2 卷积层

卷积层是卷积神经网络中的核心模块，卷积层的目的是提取输入特征图的特征，如下图所示，卷积核可以提取图像中的边缘信息。

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/2de9149eb27b2ebe6b4d16efe828b00f.png)

##### 2.6.2.1 卷积的计算方法

卷积是如何进行计算的

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/e6375c00debc53aab565c96f24818892.png)

卷积运算本质上就是在滤波器和输入数据的局部区域间做点积

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/00005b8f33209e11ced85c043da92043.png)

左上角的点计算方法：

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/a5a2b98dc72685087d425dd7bc1cdd2f.png)

同理可以计算其他各点，得到最终的卷积结果

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/d532aa52934c4dff55282f725d882220.png)

最后一点的计算方法是:

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/bbb8c95387a7bf0f9b50e0ee38eb0135.png)

##### 2.6.2.2 填充 (padding)

在上述卷积过程中，特征图比原始图减小了很多，我们可以在原图像的周围进行 padding, 来保证在卷积过程中特征图大小不变。

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/c851438a1503f837df7bb14e0e876778.png)

##### 2.6.2.3 步长 (stride)

按照步长为1来移动卷积核，计算特征图如下所示

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/c3d8b9d4f5dcfa4e44ffae712573d9d6.png)

如果我们把 stride 增大, 比如设为2，也是可以提取特征图的，如下图所示:

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/4983d93955a7f17a2e4ec6756e23f8f3.png)

##### 2.6.2.4 多通道卷积

实际中的图像都是多个通道组成的，我们怎么计算卷积呢?

 ![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/baf7260c676717e88ff5b442a3dfb89d.png)

计算方法如下: 当输入有多个通道 (channel)时 (例如图片可以有 RGB 三个通道)，卷积核需要拥有相同的 channel 数每个卷积核 channel 与输入层的对应 channel 进行卷积，将每个 channel 的卷积结果按位相加得到最终的 Feature Map

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/76e5e80e7c70af75e7272ecb9d2fc5ea.png)

##### 2.6.2.5 多卷积核卷积

如果有多个卷积核时怎么计算呢? 当有多个卷积核时，每个卷积核学习到不同的特征，对应产生包含多个 channel 的 Feature Map, 例如下图有两个 flter，所以 output 有两个 channel。

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/5a73e580750e0cc34078d2ad250c8f54.png)
##### 2.6.2.6 特征图大小

输出特征图的大小与以下参数息息相关: size: 卷积核/过滤器大小，一般会选择为奇数，比如有 $1*1$，$3*3$，$5*5*padding$: 零填充的方式 stride: 步长

那计算方法如下图所示:

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/759c77d53546035b4573a3cee6bf26dd.png)

输入特征图为5x5，卷积核为3x3，外加 padding 为1，则其输出尺寸为

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/533f5d84fac5d2969e2864d4759497a4.png)

如下图所示:

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/b5b156a028de275f34dbee1e630d8406.png)

在 tf. keras 中卷积核的使用
```python
tf.keras.layers.Conv2D(  
    filter, kernel_size, strides=(1, 1), padding='valid', activation=None  
)
```

主要参数说明如下


| 参数          | 描述                                                       |
| ----------- | -------------------------------------------------------- |
| filters     | 卷积过滤器的数量, 对应输出特征图的通道数                                    |
| kernel_size | 过滤器 flter 的大小                                            |
| strides     | 步长                                                       |
| padding     | valid: 在输入周围不进行 padding; same: padding 后使输出特征图和输入特征图形状相同 |
| activation  | 激活函数                                                     |
#### 2.6.3 池化层 (pooling)

池化层迎来降低了后续网络层的输入维度，缩减模型大小，提高计算速度，并提高了 Feature Map的鲁棒性，防止过拟合

它主要对卷积层学习到的特征图进行下采样 (subsampling)处理，主要有两种

##### 2.6.3.1 最大池化

**MaxPooling, 取窗口内的最大值作为输出**，这种方式使用较广泛

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/2365ced3477351fe5881af3723c87404.png)

##### 2.6.3.2 平均池化

**Avg Pooling, 取窗口内的所有值的均值作为输出**

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/8c5c2af3f81badd87d7967ceaffcfccd.png)

#### 2.6.4 全连接层

全连接层位于 CNN 网络的末端，经过卷积层的特征提取与池化层的降维后，将特征图转换成一维向量送入到全连接层中进行分类或回归的操作。

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/10e79e63d1b9c1af3de716554ec1e617.png)

在 tf. keras 中全连接层使用 tf. keras. dense 实现。
#### 2.6.5 卷积神经网络的搭建

我们构建卷积神经网络在 mnist 数据集上进行处理，如下图所示: LeNet-5是一个较简单的卷积神经网络, 输入的二维图像，先经过两次卷积层, 池化层，再经过全连接层，最后使用 softmax 分类作为输出层。

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/03438f7b0efda3c69ea81935b81bf879.png)


##### 2.6.5.1 数据加载

```python
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
```

##### 2.6.5.2 数据处理

卷积神经网络的输入要求是: N H W C，分别是图片数量，图片高度，图片宽度和图片的通道，因为是灰度图，通道为1.

```python
# 数据处理：num,h,w,c  
train_images = tf.reshape(train_images, (train_images.shape[0], train_images.shape[1], train_images.shape[2], 1))  
print(train_images.shape)  
# 测试集数据  
test_images = tf.reshape(test_images, (test_images.shape[0], test_images.shape[1], test_images.shape[2], 1))
```

结果

```
(60000, 28, 28, 1)
```

##### 2.6.5.3 模型构建

Lenet-5模型输入的二维图像，先经过两次卷积层, 池化层，再经过全连接层，最后使用 softmax 分类作为输出层，模型构建如下:

```python
# 模型构建  
net = tf.keras.models.Sequential([  
    # 卷积层：6个5*5的卷积核，激活是sigmoid  
    tf.keras.layers.Conv2D(filters=6, kernel_size=5, activation='sigmoid', input_shape=(28, 28, 1)),  
    # 最大池化  
    tf.keras.layers.MaxPool2D(pool_size=2, strides=2),  
    # 卷积层：16个5*5的卷积核，激活是sigmoid  
    tf.keras.layers.Conv2D(filters=16, kernel_size=5, activation='sigmoid'),  
    # 最大池化  
    tf.keras.layers.MaxPool2D(pool_size=2, strides=2),  
    # 维度调整为1为数据  
    tf.keras.layers.Flatten(),  
    # 全卷积层，激活sigmoid  
    tf.keras.layers.Dense(120, activation='sigmoid'),  
    # 全卷积层，激活sigmoid  
    tf.keras.layers.Dense(84, activation='sigmoid'),  
    # 全卷积层，激活softmax  
    tf.keras.layers.Dense(10, activation='softmax')  
])  
net.summary()
```

```
Model: "sequential_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_2 (Conv2D)           (None, 24, 24, 6)         156       
                                                                 
 max_pooling2d_2 (MaxPoolin  (None, 12, 12, 6)         0         
 g2D)                                                            
                                                                 
 conv2d_3 (Conv2D)           (None, 8, 8, 16)          2416      
                                                                 
 max_pooling2d_3 (MaxPoolin  (None, 4, 4, 16)          0         
 g2D)                                                            
                                                                 
 flatten_1 (Flatten)         (None, 256)               0         
                                                                 
 dense_3 (Dense)             (None, 120)               30840     
                                                                 
 dense_4 (Dense)             (None, 84)                10164     
                                                                 
 dense_5 (Dense)             (None, 10)                850       
                                                                 
=================================================================
Total params: 44426 (173.54 KB)
Trainable params: 44426 (173.54 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
```

```python
tf.keras.utils.plot_model(net)
```

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/85ba6e24120dca9b93d9945cd5c9a35f.png)

##### 2.6.5.4 模型编译

设置优化器和损失函数:

```python
# 优化器  
optimizer = tf.keras.optimizers.SGD(learning_rate=0.9)  
# 模型编译：损失函数，优化器和评价指标  
net.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])
```

##### 2.6.5.5 模型训练

```python
# 模型训练  
net.fit(train_images, train_labels, epochs=5, validation_split=0.1)
```

训练过程

```
Epoch 1/5
1688/1688 [==============================] - 8s 5ms/step - loss: 0.0644 - accuracy: 0.9792 - val_loss: 0.0532 - val_accuracy: 0.9837
Epoch 2/5
1688/1688 [==============================] - 8s 5ms/step - loss: 0.0589 - accuracy: 0.9811 - val_loss: 0.0813 - val_accuracy: 0.9750
Epoch 3/5
1688/1688 [==============================] - 8s 5ms/step - loss: 0.0546 - accuracy: 0.9830 - val_loss: 0.0605 - val_accuracy: 0.9807
Epoch 4/5
1688/1688 [==============================] - 8s 5ms/step - loss: 0.0470 - accuracy: 0.9849 - val_loss: 0.0490 - val_accuracy: 0.9865
Epoch 5/5
1688/1688 [==============================] - 8s 5ms/step - loss: 0.0399 - accuracy: 0.9873 - val_loss: 0.0595 - val_accuracy: 0.9817

<keras.src.callbacks.History at 0x29c2c9b6a10>
```

##### 2.6.5.6 模型评估

```python
# 模型评估  
score = net.evaluate(test_images, test_labels, verbose=1)  
print('Test accuray:', score[1])
```

```
313/313 [==============================] - 1s 3ms/step - loss: 0.0571 - accuracy: 0.9807
Test accuray: 0.9807000160217285
```

与使用全连接网络相比，准确度提高了很多


## 3. 图像分类

### 3.1 图像分类简介
图像分类实质上就是从给定的类别集合中为图像分配对应标签的任务。也就是说我们的任务是分析一个输入图像并返回一个该图像类别的标签。

假定类别集为 categories ={dog, cat, panda)，之后我们提供一张图片给分类模型，如下图所示:

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/5dfc1240a5b849a29895d80ae1f8d066.png)

分类模型给图像分配多个标签，每个标签的概率值不同，如 dog:95%，cat:4%，panda:1%，根据概率值的大小将该图片分类为 dog，那就完成了图像分类的任务。

#### 3.1.1 常用数据集 

**mnist 数据集**

该数据集是手写数字0-9的集合，共有60k 训练图像、10k 测试图像、10个类别、图像大小28x28x1。我们可以通过 tf. keras 直接加载该数据集:
```python
from tensorflow.keras.datasets import mnist
# 加载mnist数据集
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
```

**CIFAR-10 和 CIFAR-100**

CIFAR-10数据集5万张训练图像、1万张测试图像、10个类别、每个类别有6k 个图像，图像大小32x32x3。下图举了10个类，每一类随机展示了10张图片:

![](https://picgo-img-repo.oss-cn-beijing.aliyuncs.com/img/3c9dd2b32e525d45d9f8aeea91e7d18b.png)

CIFAR-100数据集也是有5万张训练图像、1万张测试图像、包含100个类别、图像大小32x32x3。

在 tf. keras 中使用
```python
import tensorflow as tf
from tensorflow.keras.datasets import cifar10, cifar100
# 加载cifar10数据集
(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()
# 加载cifar100数据集
(train_images, train_labels), (test_images, test_labels) = cifar100.load_data()
```

**ImageNet**

lmageNet 数据集是 LSVRC 竞赛使用的是数据集，由斯坦福大学李飞飞教授主导，包含了超过1400万张全尺寸的有标记图片，大约有22000个类别的数据。ILSVRC 全称 ImageNetLarge-Scale Visua Recognition Challenge，是视觉领域最受追捧也是最具权威的学术竞赛之一，代表了图像领域的最高水平。从2010年开始举办到2017年最后一届，使用 ImageNet 数据集的一个子集，总共有1000类。

